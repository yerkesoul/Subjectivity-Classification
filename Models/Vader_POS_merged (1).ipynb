{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370b1e2a",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1adfeeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all needed libraries and packages\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import StanfordTagger\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from keras import Input, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Concatenate, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from keras.layers import Bidirectional, InputLayer, SimpleRNN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from itertools import chain, repeat, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c329d4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYT-EDU original features: 1881\n",
      "NYT-FIN original features: 3100\n",
      "NYT-LAW original features: 3553\n",
      "NYT-Med original features: 1743\n",
      "NYT-MILL original features: 2132\n",
      "NYT-POL original features: 6886\n"
     ]
    }
   ],
   "source": [
    "#Importing already filtered out datasets from New York Times\n",
    "nyt_edu_original= list(open(\"/data/output_txt/nyt-edu.txt\"))\n",
    "print(\"NYT-EDU original features:\",len(nyt_edu_original ))\n",
    "nyt_fin_original= list(open(\"/data/output_txt/nyt-fin.txt\"))\n",
    "print(\"NYT-FIN original features:\",len(nyt_fin_original))\n",
    "nyt_law_original= list(open(\"/data/output_txt/nyt-law.txt\"))\n",
    "print(\"NYT-LAW original features:\",len(nyt_law_original))\n",
    "nyt_med_original = list(open(\"/data/output_txt/nyt-med.txt\"))\n",
    "print(\"NYT-Med original features:\",len(nyt_med_original))\n",
    "nyt_mil_original= list(open(\"/data/output_txt/nyt-mil.txt\"))\n",
    "print(\"NYT-MILL original features:\",len(nyt_mil_original))\n",
    "nyt_pol_original = list(open(\"/data/output_txt/nyt-pol.txt\"))\n",
    "print(\"NYT-POL original features:\",len(nyt_pol_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26946689",
   "metadata": {},
   "source": [
    "# VADER for sentiment analysis.Testing model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb78e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3942626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All helper  functions needeed for implementing the Vader model\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "#Vader gives a dictionary as output we need to transfer it to a integer\n",
    "def format_output(output_dict):\n",
    "    if(output_dict['compound']>= 0.05):\n",
    "        polarity =1 #positive=1\n",
    "    elif(output_dict['compound']<= -0.05):\n",
    "        polarity =2 #negative=2\n",
    "    else:\n",
    "        polarity =3 #neural=3\n",
    "    return polarity\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    output_dict =  sid.polarity_scores(text)\n",
    "    return format_output(output_dict)\n",
    "\n",
    "#As the number of sentences are different we need to pad to 100 sentences at maximun.\n",
    "def pad_infinite(iterable, padding=None):\n",
    "    return chain(iterable, repeat(padding))\n",
    "\n",
    "def pad(iterable, size, padding=None):\n",
    "    return list(islice(pad_infinite(iterable, padding), size))\n",
    "\n",
    "#The main function of sentiment extraction.\n",
    "def sentiment_dataset_extraction(example_dataset):\n",
    "    main_label_list=[]\n",
    "    sentiment_labels_list=[]\n",
    "    for s in example_dataset:\n",
    "        text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "        split_text = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
    "        if len(split_text)<=100:\n",
    "            text_sentiment=[]\n",
    "            label=s.split(\"\\t\")[0]\n",
    "            if label=='editorial':\n",
    "                label=0\n",
    "            elif label=='news':\n",
    "                label=1\n",
    "            for sent in split_text:\n",
    "                sentence_sentiment=predict_sentiment(sent)\n",
    "                text_sentiment.append(sentence_sentiment)\n",
    "            padded_sentence=pad(text_sentiment,100,0)\n",
    "            sentiment_labels_list.append(padded_sentence)\n",
    "            main_label_list.append(label)\n",
    "    return sentiment_labels_list,main_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17385bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the sentiment fromt the dataset\n",
    "#First variable is list with sentiment tensors and the second variable is a list with labels.\n",
    "edu_sentiments,edu_labels=sentiment_dataset_extraction(nyt_edu_original)\n",
    "fin_sentiments,fin_labels=sentiment_dataset_extraction(nyt_fin_original)\n",
    "law_sentiments,law_labels=sentiment_dataset_extraction(nyt_law_original)\n",
    "med_sentiments,med_labels=sentiment_dataset_extraction(nyt_med_original)\n",
    "mil_sentiments,mil_labels=sentiment_dataset_extraction(nyt_mil_original)\n",
    "pol_sentiments,pol_labels=sentiment_dataset_extraction(nyt_pol_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e69657f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 100, 128)          384       \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,409\n",
      "Trainable params: 33,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#The architecture of Sentiment analysis model.Binary classification.\n",
    "input_arg = Input(shape=(100,))\n",
    "model_arg = Embedding(3, 128)(input_arg)\n",
    "model_arg = SimpleRNN(128, dropout=0.5)(model_arg)\n",
    "dense_pred = (Dense(1, activation='sigmoid'))(model_arg)\n",
    "model_sentiment= Model(inputs=input_arg, outputs=dense_pred)\n",
    "model_sentiment.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_score])\n",
    "print(model_sentiment.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff0a4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 19s 103ms/step - loss: 0.5364 - accuracy: 0.7742 - f1_score: 0.8687 - val_loss: 0.5373 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 17s 102ms/step - loss: 0.5346 - accuracy: 0.7782 - f1_score: 0.8728 - val_loss: 0.5319 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 17s 101ms/step - loss: 0.5314 - accuracy: 0.7782 - f1_score: 0.8733 - val_loss: 0.5348 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 18s 102ms/step - loss: 0.5366 - accuracy: 0.7782 - f1_score: 0.8732 - val_loss: 0.5327 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 17s 102ms/step - loss: 0.5339 - accuracy: 0.7782 - f1_score: 0.8730 - val_loss: 0.5454 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5730fc9790>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation data extraction.Traning data: NYT politics dataset.\n",
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent= train_test_split(pol_sentiments, pol_labels, \n",
    "    test_size=0.2, random_state= 42)\n",
    "#Fit the model to the actual data.\n",
    "model_sentiment.fit(np.array(X_train_sent),np.array(y_train_sent),\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=(np.array(X_test_sent),np.array(y_test_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18f09845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyt_edu\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.5881 - accuracy: 0.7261 - f1_score: 0.8364\n",
      "Test score: 0.5881454348564148\n",
      "Test accuracy: 0.7261320352554321\n",
      "F1 score: 0.8364138603210449\n",
      "nyt_fin\n",
      "96/96 [==============================] - 2s 19ms/step - loss: 0.5048 - accuracy: 0.8236 - f1_score: 0.9012\n",
      "Test score: 0.5047732591629028\n",
      "Test accuracy: 0.8235870599746704\n",
      "F1 score: 0.9012267589569092\n",
      "nyt_law\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 0.5803 - accuracy: 0.7355 - f1_score: 0.8446\n",
      "Test score: 0.5802714228630066\n",
      "Test accuracy: 0.7355113625526428\n",
      "F1 score: 0.8446060419082642\n",
      "nyt_med\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 0.5796 - accuracy: 0.7357 - f1_score: 0.8435\n",
      "Test score: 0.5796002149581909\n",
      "Test accuracy: 0.7357268929481506\n",
      "F1 score: 0.8434920907020569\n",
      "nyt_mil\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.5288 - accuracy: 0.7956 - f1_score: 0.8846\n",
      "Test score: 0.5287598967552185\n",
      "Test accuracy: 0.7955513596534729\n",
      "F1 score: 0.8845686912536621\n"
     ]
    }
   ],
   "source": [
    "#Test on NYT education, NYT finances ,NYT law,NYT medicine ,NYT military\n",
    "for features, labels, name in zip([np.array(edu_sentiments),np.array(fin_sentiments),np.array(law_sentiments),np.array(med_sentiments),np.array(mil_sentiments)],[np.array(edu_labels),np.array(fin_labels),np.array(law_labels),np.array(med_labels),np.array(mil_labels)],['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    score, acc,f1= model_sentiment.evaluate(features, labels, batch_size=32)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df792a94",
   "metadata": {},
   "source": [
    "# Stanford POS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323443aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The English Penn Treebank tagset is used for Stanford POS model,we need to tranfser them to numbers.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "pos_tags={ \"CC\":1,\"CD\":2,\"DT\":3,\"EX\":4,\"FW\":5,\n",
    "\"IN\":6,\"JJ\":7,\"JJR\":8,\"JJS\":9,\"LS\":10,\"MD\":11,\n",
    "\"NN\":12,\"NNS\":13,\"NNP\":14,\"NNPS\":15,\"PDT\":16,\"POS\":17,\n",
    "\"PRP\":18,\"PRP$\":19,\"RB\":20,\"RBR\":21,\"RBS\":22,\"RP\":23,\n",
    "\"SYM\":24,\"TO\":25,\"UH\":26,\"VB\":27,\"VBD\":28,\"VBG\":29,\n",
    "\"VBN\":30,\"VBP\":31,\"VBZ\":32,\"WDT\":33,\"WP\":34,\"WP$\":35,\"WRB\":36}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486978f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the percentage of documents in all documents that have more than 100 sentences? 1.2593936252915263\n"
     ]
    }
   ],
   "source": [
    "#How many documents there are that contain more than 100 sentences in one document?\n",
    "def check_sentence_length(example_sets):\n",
    "    check_lemmas={}\n",
    "    for example_set in example_sets:\n",
    "        for s in example_set:\n",
    "            pos_list_text=[]\n",
    "            label=s.split(\"\\t\")[0]\n",
    "            if label=='editorial':\n",
    "                label=0\n",
    "            elif label=='news':\n",
    "                label=1\n",
    "            text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "            split_text = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
    "            if len(split_text) not in check_lemmas:\n",
    "                check_lemmas[len(split_text)]=0\n",
    "            check_lemmas[len(split_text)]+=1\n",
    "    return check_lemmas\n",
    "\n",
    "#Imply the model\n",
    "sentence_length_dict=check_sentence_length((nyt_edu_original,nyt_fin_original,nyt_law_original,nyt_med_original,nyt_mil_original,nyt_pol_original))\n",
    "count_more_100=0\n",
    "general_number_documents=sum(sentence_length_dict.values())\n",
    "for k,v in sentence_length_dict.items():\n",
    "    if k>100:\n",
    "        count_more_100+=v\n",
    "percentage_less_100=(count_more_100/general_number_documents)*100\n",
    "print(\"What is the percentage of documents in all documents that have more than 100 sentences?\",percentage_less_100)\n",
    "#This means that more than 98% of the whole dataset contains of sentences with length less than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8286e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofzeros = [0] *100\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "def pos_tagger(pos_example_dataset):\n",
    "    pos_data=[]\n",
    "    pos_label=[]\n",
    "    for s in pos_example_dataset:\n",
    "        pos_list_text=[]\n",
    "        text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "        split_text = nltk.sent_tokenize(text)\n",
    "        if len(split_text)<=100:\n",
    "            for sent in split_text:\n",
    "                pos_list_sentence=[]\n",
    "                pos_analyzed=nltk.pos_tag(tokenizer.tokenize(sent))\n",
    "                for word in pos_analyzed:\n",
    "                    try:\n",
    "                        pos_list_sentence.append(pos_tags[word[1]])\n",
    "                    except:\n",
    "                        pass\n",
    "                pos_list_sentence=pad(pos_list_sentence,100,0)\n",
    "                pos_list_text.append(pos_list_sentence)\n",
    "            label=s.split(\"\\t\")[0]\n",
    "            if label=='editorial':\n",
    "                label=0\n",
    "            elif label=='news':\n",
    "                label=1\n",
    "            if len(pos_list_text)<100:\n",
    "                pos_list_text=pad(pos_list_text,100,listofzeros)\n",
    "            pos_tensor=tf.convert_to_tensor(pos_list_text)\n",
    "            pos_data.append(pos_tensor)\n",
    "            pos_label.append(label)\n",
    "    return pos_data,pos_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9d839f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 19:17:58.891155: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 19:17:59.816127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10413 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "edu_pos_data,edu_pos_labels=pos_tagger(nyt_edu_original)\n",
    "fin_pos_data,fin_pos_labels=pos_tagger(nyt_fin_original)\n",
    "law_pos_data,law_pos_labels=pos_tagger(nyt_law_original)\n",
    "med_pos_data,med_pos_labels=pos_tagger(nyt_med_original)\n",
    "mil_pos_data,mil_pos_labels=pos_tagger(nyt_mil_original)\n",
    "pol_pos_data,pol_pos_labels=pos_tagger(nyt_pol_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b69dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100)]        0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 128)               29312     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,441\n",
      "Trainable params: 29,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Model of POS.\n",
    "input_arg = Input(shape=pol_pos_data[0].shape)\n",
    "model_arg= SimpleRNN(128, dropout=0.1)(input_arg)\n",
    "dense_pred = (Dense(1, activation='sigmoid'))(model_arg)\n",
    "model_pos= Model(inputs=input_arg, outputs=dense_pred)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_pos.compile(loss='binary_crossentropy', optimizer=opt , metrics=['accuracy',f1_score])\n",
    "print(model_pos.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "919a1e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 14s 74ms/step - loss: 0.5873 - accuracy: 0.7275 - f1_score: 0.8294 - val_loss: 0.5407 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 12s 70ms/step - loss: 0.5527 - accuracy: 0.7712 - f1_score: 0.8677 - val_loss: 0.5490 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 12s 69ms/step - loss: 0.5429 - accuracy: 0.7758 - f1_score: 0.8714 - val_loss: 0.5763 - val_accuracy: 0.7035 - val_f1_score: 0.8182\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 12s 71ms/step - loss: 0.5520 - accuracy: 0.7720 - f1_score: 0.8683 - val_loss: 0.5395 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 12s 72ms/step - loss: 0.5471 - accuracy: 0.7782 - f1_score: 0.8733 - val_loss: 0.5408 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f57f00f1700>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos= train_test_split(pol_pos_data,pol_pos_labels, \n",
    "    test_size=0.2, random_state= 42)\n",
    "model_pos.fit(np.array(X_train_pos),np.array(y_train_pos),\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=(np.array(X_test_pos),np.array(y_test_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52890c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyt_edu\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.6249 - accuracy: 0.7261 - f1_score: 0.8364\n",
      "Test score: 0.6248546838760376\n",
      "Test accuracy: 0.7261320352554321\n",
      "F1 score: 0.8364138603210449\n",
      "nyt_fin\n",
      "96/96 [==============================] - 2s 18ms/step - loss: 0.4790 - accuracy: 0.8236 - f1_score: 0.9012\n",
      "Test score: 0.4789609909057617\n",
      "Test accuracy: 0.8235870599746704\n",
      "F1 score: 0.9012267589569092\n",
      "nyt_law\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 0.6034 - accuracy: 0.7355 - f1_score: 0.8446\n",
      "Test score: 0.603351891040802\n",
      "Test accuracy: 0.7355113625526428\n",
      "F1 score: 0.8446060419082642\n",
      "nyt_med\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.6050 - accuracy: 0.7357 - f1_score: 0.8435\n",
      "Test score: 0.6050265431404114\n",
      "Test accuracy: 0.7357268929481506\n",
      "F1 score: 0.8434920907020569\n",
      "nyt_mil\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.5163 - accuracy: 0.7956 - f1_score: 0.8846\n",
      "Test score: 0.5162953734397888\n",
      "Test accuracy: 0.7955513596534729\n",
      "F1 score: 0.8845686912536621\n"
     ]
    }
   ],
   "source": [
    "for features, labels, name in zip([np.array(edu_pos_data),np.array(fin_pos_data),np.array(law_pos_data),np.array(med_pos_data),np.array(mil_pos_data)],[np.array(edu_pos_labels),np.array(fin_pos_labels),np.array(law_pos_labels),np.array(med_pos_labels),np.array(mil_pos_labels)],['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    score, acc,f1= model_pos.evaluate(features, labels, batch_size=32)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e84d6df",
   "metadata": {},
   "source": [
    "# VADER+POS merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8551a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 100, 128)     384         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 100, 100)]   0           []                               \n",
      "                                                                                                  \n",
      " simple_rnn_5 (SimpleRNN)       (None, 128)          32896       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " simple_rnn_6 (SimpleRNN)       (None, 128)          29312       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256)          0           ['simple_rnn_5[0][0]',           \n",
      "                                                                  'simple_rnn_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            257         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62,849\n",
      "Trainable params: 62,849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#The architecture of  VADER+POS merged\n",
    "input_sentiment = Input(shape=(100,))\n",
    "model_sentiment = Embedding(3, 128)(input_sentiment)\n",
    "model_sentiment = SimpleRNN(128, dropout=0.2)(model_sentiment)\n",
    "\n",
    "input_pos= Input(pol_pos_data[0].shape)\n",
    "model_pos= SimpleRNN(128, dropout=0.1)(input_pos)\n",
    "\n",
    "merged = Concatenate()([model_sentiment, model_pos])\n",
    "dense_pred = (Dense(1, activation='sigmoid'))(merged)\n",
    "\n",
    "model_merged= Model(inputs=[input_sentiment,input_pos], outputs=dense_pred)\n",
    "model_merged.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_score])\n",
    "print(model_merged.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "678ff294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to transfer the list to a tensort so we can combine with POS data.\n",
    "X_train_sent=tf.stack(X_train_sent, axis=0)\n",
    "X_test_sent=tf.stack(X_test_sent, axis=0)\n",
    "X_train_pos=tf.stack(X_train_pos, axis=0)\n",
    "X_test_pos=tf.stack(X_test_pos, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55c438fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#education tranform into a tensor\n",
    "edu_sentiments=tf.stack(edu_sentiments, axis=0)\n",
    "edu_labels=np.array(edu_labels)\n",
    "#finances tranform into a tensor\n",
    "fin_sentiments=tf.stack(fin_sentiments, axis=0)\n",
    "fin_labels=np.array(fin_labels)\n",
    "#law tranform into a tensor\n",
    "law_sentiments=tf.stack(law_sentiments, axis=0)\n",
    "law_labels=np.array(law_labels)\n",
    "#medicine tranform into a tensor\n",
    "med_sentiments=tf.stack(med_sentiments, axis=0)\n",
    "med_labels=np.array(med_labels)\n",
    "#military tranform into a tensor\n",
    "mil_sentiments=tf.stack(mil_sentiments, axis=0)\n",
    "mil_labels=np.array(mil_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "259bed19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 28s 150ms/step - loss: 0.5394 - accuracy: 0.7767 - f1_score: 0.8711 - val_loss: 0.5322 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 25s 147ms/step - loss: 0.5332 - accuracy: 0.7780 - f1_score: 0.8733 - val_loss: 0.5640 - val_accuracy: 0.7665 - val_f1_score: 0.8650\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 25s 147ms/step - loss: 0.5478 - accuracy: 0.7705 - f1_score: 0.8682 - val_loss: 0.5412 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.5375 - accuracy: 0.7780 - f1_score: 0.8734 - val_loss: 0.5355 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.5336 - accuracy: 0.7782 - f1_score: 0.8736 - val_loss: 0.5328 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f574c23e370>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "model_merged.fit([X_train_sent,X_train_pos],np.array(y_train_sent),\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([X_test_sent, X_test_pos ],np.array(y_test_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b0ca131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyt_edu\n",
      "58/58 [==============================] - 1s 21ms/step - loss: 0.6002 - accuracy: 0.7261 - f1_score: 0.8364\n",
      "Test score: 0.6002344489097595\n",
      "Test accuracy: 0.7261320352554321\n",
      "F1 score: 0.8364138603210449\n",
      "nyt_fin\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 0.4690 - accuracy: 0.8236 - f1_score: 0.9012\n",
      "Test score: 0.46895769238471985\n",
      "Test accuracy: 0.8235870599746704\n",
      "F1 score: 0.9012267589569092\n",
      "nyt_law\n",
      "110/110 [==============================] - 3s 22ms/step - loss: 0.5875 - accuracy: 0.7355 - f1_score: 0.8446\n",
      "Test score: 0.587472677230835\n",
      "Test accuracy: 0.7355113625526428\n",
      "F1 score: 0.8446060419082642\n",
      "nyt_med\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.5871 - accuracy: 0.7357 - f1_score: 0.8435\n",
      "Test score: 0.5870500802993774\n",
      "Test accuracy: 0.7357268929481506\n",
      "F1 score: 0.8434920907020569\n",
      "nyt_mil\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.5066 - accuracy: 0.7956 - f1_score: 0.8846\n",
      "Test score: 0.5065819621086121\n",
      "Test accuracy: 0.7955513596534729\n",
      "F1 score: 0.8845686912536621\n"
     ]
    }
   ],
   "source": [
    "for features, labels, name in zip([[edu_sentiments,np.array(edu_pos_data)],[fin_sentiments,np.array(fin_pos_data)],[law_sentiments,np.array(law_pos_data)],[med_sentiments,np.array(med_pos_data)],[mil_sentiments,np.array(mil_pos_data)]],[edu_labels,fin_labels,law_labels,med_labels,mil_labels],['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    score, acc,f1= model_merged.evaluate(features, labels, batch_size=32)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
