{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0daabe",
   "metadata": {},
   "source": [
    "# Import argumentative features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5e07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all needed libraries and packages\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import StanfordTagger\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pickle\n",
    "import os\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4ea485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYT publishers and dataset size:\n",
      "NYT-EDU original features: 1881\n",
      "NYT-FIN original features: 3100\n",
      "NYT-LAW original features: 3553\n",
      "NYT-Med original features: 1743\n",
      "NYT-MILL original features: 2132\n",
      "NYT-POL original features: 6886\n"
     ]
    }
   ],
   "source": [
    "#Importing already filtered out datasets from New York Times\n",
    "print(\"NYT publishers and dataset size:\")\n",
    "nyt_edu_original= list(open(\"/data/output_txt/nyt-edu.txt\"))\n",
    "print(\"NYT-EDU original features:\",len(nyt_edu_original ))\n",
    "nyt_fin_original= list(open(\"/data/output_txt/nyt-fin.txt\"))\n",
    "print(\"NYT-FIN original features:\",len(nyt_fin_original))\n",
    "nyt_law_original= list(open(\"/data/output_txt/nyt-law.txt\"))\n",
    "print(\"NYT-LAW original features:\",len(nyt_law_original))\n",
    "nyt_med_original = list(open(\"/data/output_txt/nyt-med.txt\"))\n",
    "print(\"NYT-Med original features:\",len(nyt_med_original))\n",
    "nyt_mil_original= list(open(\"/data/output_txt/nyt-mil.txt\"))\n",
    "print(\"NYT-MILL original features:\",len(nyt_mil_original))\n",
    "nyt_pol_original = list(open(\"/data/output_txt/nyt-pol.txt\"))\n",
    "print(\"NYT-POL original features:\",len(nyt_pol_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385fd8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_arg_features(dataset):\n",
    "    arg_features=[]\n",
    "    arg_labels=[]\n",
    "    arg_features_dict={}\n",
    "    for s in dataset:\n",
    "        text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "        text=text.replace('\"',\"\")\n",
    "        tokenized=nltk.sent_tokenize(text)\n",
    "        if len(tokenized)<=100:\n",
    "            sequence=literal_eval(s.split(\"\\t\")[2].split(\"\\n\")[0])\n",
    "            label=s.split(\"\\t\")[0]\n",
    "            if label=='editorial':\n",
    "                label=0\n",
    "            elif label=='news':\n",
    "                label=1\n",
    "            arg_features.append(sequence)\n",
    "            arg_labels.append(label)\n",
    "            arg_features_dict[text]=(sequence,label)\n",
    "    return arg_features_dict,arg_features,arg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "916d1409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYT publishers and dataset size of argumentative features with 3 labels:Claim, Premises,None\n",
      "NYT-EDU argumentative features: 1833\n",
      "NYT-FIN argumentative features: 3061\n",
      "NYfT-LAW argumentative features: 3520\n",
      "NYT-Med argumentative features: 1699\n",
      "NYT-MILL argumentative features: 2113\n",
      "NYT-POL argumentative features: 6826\n"
     ]
    }
   ],
   "source": [
    "#Argumentative features.3 labels\n",
    "print(\"NYT publishers and dataset size of argumentative features with 3 labels:Claim, Premises,None\")\n",
    "nyt_edu_arg = list(open(\"/data/output_txt/nyt-edu-argfeat.txt\"))\n",
    "edu_arg_3,edu_arg_3_features,edu_arg_3_labels=extract_arg_features(nyt_edu_arg)\n",
    "print(\"NYT-EDU argumentative features:\",len(edu_arg_3))\n",
    "nyt_fin_arg = list(open(\"/data/output_txt/nyt-fin-argfeat.txt\"))\n",
    "fin_arg_3,fin_arg_3_features,fin_arg_3_labels=extract_arg_features(nyt_fin_arg)\n",
    "print(\"NYT-FIN argumentative features:\",len(fin_arg_3))\n",
    "nyt_law_arg = list(open(\"/data/output_txt/nyt-law-argfeat.txt\"))\n",
    "law_arg_3,law_arg_3_features,law_arg_3_labels=extract_arg_features(nyt_law_arg)\n",
    "print(\"NYfT-LAW argumentative features:\",len(law_arg_3))\n",
    "nyt_med_arg = list(open(\"/data/output_txt/nyt-med-argfeat.txt\"))\n",
    "med_arg_3,med_arg_3_features,med_arg_3_labels=extract_arg_features(nyt_med_arg)\n",
    "print(\"NYT-Med argumentative features:\",len(med_arg_3))\n",
    "nyt_mil_arg = list(open(\"/data/output_txt/nyt-mil-argfeat.txt\"))\n",
    "mil_arg_3,mil_arg_3_features,mil_arg_3_labels=extract_arg_features(nyt_mil_arg)\n",
    "print(\"NYT-MILL argumentative features:\",len(mil_arg_3))\n",
    "nyt_pol_arg = list(open(\"/data/output_txt/nyt-pol-argfeat.txt\"))\n",
    "pol_arg_3,pol_arg_3_features,pol_arg_3_labels=extract_arg_features(nyt_pol_arg)\n",
    "print(\"NYT-POL argumentative features:\",len(pol_arg_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d1a03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYT publishers and dataset size of argumentative features with 3 labels:'assumption','anecdote','testimony','statistics','other','common-ground'\n",
      "NYT-EDU arg features: 1831\n",
      "NYT-FIN arg features: 3059\n",
      "NYT-LAW arg features: 3520\n",
      "NYT-Med arg features: 1699\n",
      "NYT-MILL arg features: 2113\n",
      "NYT-POL arg features: 6826\n"
     ]
    }
   ],
   "source": [
    "#Argumentative features.6 labels\n",
    "print(\"NYT publishers and dataset size of argumentative features with 3 labels:'assumption','anecdote','testimony','statistics','other','common-ground'\")\n",
    "nyt_edu_6_arg = list(open(\"nyt-edu-argfeat-6.txt\"))\n",
    "edu_arg_6,edu_arg_6_features,edu_arg_6_labels=extract_arg_features(nyt_edu_6_arg)\n",
    "print(\"NYT-EDU arg features:\",len(edu_arg_6))\n",
    "nyt_fin_6_arg = list(open(\"/data/output_txt/nyt-fin-argfeat-6.txt\"))\n",
    "fin_arg_6,fin_arg_6_features,fin_arg_6_labels=extract_arg_features(nyt_fin_6_arg)\n",
    "print(\"NYT-FIN arg features:\",len(fin_arg_6))\n",
    "nyt_law_6_arg = list(open(\"/data/output_txt/nyt-law-argfeat-6.txt\"))\n",
    "law_arg_6,law_arg_6_features,law_arg_6_labels=extract_arg_features(nyt_law_6_arg)\n",
    "print(\"NYT-LAW arg features:\",len(law_arg_6))\n",
    "nyt_med_6_arg = list(open(\"/data/output_txt/nyt-med-argfeat-6.txt\"))\n",
    "med_arg_6,med_arg_6_features,med_arg_6_labels=extract_arg_features(nyt_med_6_arg)\n",
    "print(\"NYT-Med arg features:\",len(med_arg_6))\n",
    "nyt_mil_6_arg = list(open(\"/data/output_txt/nyt-mil-argfeat-6.txt\"))\n",
    "mil_arg_6,mil_arg_6_features,mil_arg_6_labels=extract_arg_features(nyt_mil_6_arg)\n",
    "print(\"NYT-MILL arg features:\",len(mil_arg_6))\n",
    "nyt_pol_6_arg = list(open(\"/data/output_txt/nyt-pol-argfeat-6.txt\"))\n",
    "pol_arg_6,pol_arg_6_features,pol_arg_6_labels=extract_arg_features(nyt_pol_6_arg)\n",
    "print(\"NYT-POL arg features:\",len(pol_arg_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde59c70",
   "metadata": {},
   "source": [
    "# Import BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011c3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(name):\n",
    "    directory = '/data/BertEmbeddings/'+str(name)\n",
    "    # Create empty dictionary to save data\n",
    "    bert_dict= {}\n",
    "    # Loop over files and read pickles\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.pickle'):\n",
    "            with open(str(\"/data/BertEmbeddings/\"+str(name)+\"/\"+str(file)), 'rb') as f:\n",
    "                bert_f=pickle.load(f)\n",
    "                article= bert_f['article']\n",
    "                article=article.replace('\"',\"\")\n",
    "                tokenized=nltk.sent_tokenize(article)\n",
    "                if len(tokenized)<=100:\n",
    "                    label= bert_f['label']\n",
    "                    if label=='editorial':\n",
    "                        label=0\n",
    "                    elif label=='news':\n",
    "                        label=1\n",
    "                    bert_emb= bert_f['bert_emb'][0]\n",
    "                    bert_dict[article] =tf.convert_to_tensor(bert_emb.cpu())\n",
    "    return bert_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a3a02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Arg. Feature=Embeddings: Education True\n",
      "Length Arg. Feature=Embeddings: Finances- True\n",
      "Length Arg. Feature=Embeddings: Law- True\n",
      "Length Arg. Feature=Embeddings: Medicine- True\n",
      "Length Arg. Feature=Embeddings: Military- True\n",
      "Length Arg. Feature=Embeddings: Politics- True\n"
     ]
    }
   ],
   "source": [
    "#education\n",
    "edu_bert=get_bert_embeddings(\"NytEduBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Education\",len(edu_arg_3)==len(edu_bert))\n",
    "#finances\n",
    "fin_bert=get_bert_embeddings(\"NytFinBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Finances-\",len(fin_arg_3)==len(fin_bert))\n",
    "#law \n",
    "law_bert=get_bert_embeddings(\"NytLawBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Law-\",len(law_arg_3)==len(law_bert))\n",
    "#medicine \n",
    "med_bert=get_bert_embeddings(\"NytMedBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Medicine-\",len(med_arg_3)==len(med_bert))\n",
    "#military\n",
    "mil_bert=get_bert_embeddings(\"NytMillBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Military-\",len(mil_arg_3)==len(mil_bert))\n",
    "#politics\n",
    "pol_bert=get_bert_embeddings(\"NytPolBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Politics-\",len(pol_arg_3)==len(pol_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "918d9d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(unsorted_arg_dataset,unsorted_bert_dataset):\n",
    "    sorted_keys=sorted(unsorted_arg_dataset.keys())\n",
    "    sorted_bert= []\n",
    "    sorted_arg = []\n",
    "    labels=[]\n",
    "    for key in sorted_keys:\n",
    "        tensor=unsorted_bert_dataset[key]\n",
    "        sorted_bert.append(tensor)\n",
    "    for key in sorted_keys:\n",
    "        sorted_arg.append(tf.convert_to_tensor(unsorted_arg_dataset[key][0]))\n",
    "        labels.append(unsorted_arg_dataset[key][1])\n",
    "    return sorted_arg,sorted_bert,labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b164fb32",
   "metadata": {},
   "source": [
    "----------------Extracting features and embeddings----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abb73adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#education\n",
    "edu_features=extract_features(edu_arg_3,edu_bert)[0]\n",
    "edu_embedding=extract_features(edu_arg_3,edu_bert)[1]\n",
    "edu_labels=extract_features(edu_arg_3,edu_bert)[2]\n",
    "#edu_bert.clear()\n",
    "#torch.cuda.empty_cache()\n",
    "#finances\n",
    "fin_features=extract_features(fin_arg_3,fin_bert)[0]\n",
    "fin_embedding=extract_features(fin_arg_3,fin_bert)[1]\n",
    "fin_labels=extract_features(fin_arg_3,fin_bert)[2]\n",
    "#fin_bert.clear()\n",
    "#torch.cuda.empty_cache()\n",
    "#law\n",
    "law_features=extract_features(law_arg_3,law_bert)[0]\n",
    "law_embedding=extract_features(law_arg_3,law_bert)[1]\n",
    "law_labels=extract_features(law_arg_3,law_bert)[2]\n",
    "#law_bert.clear()\n",
    "#torch.cuda.empty_cache()\n",
    "#medicine\n",
    "medicine_features=extract_features(med_arg_3,med_bert)[0]\n",
    "medicine_embedding=extract_features(med_arg_3,med_bert)[1]\n",
    "medicine_labels=extract_features(med_arg_3,med_bert)[2]\n",
    "#med_bert.clear()\n",
    "#torch.cuda.empty_cache()\n",
    "#military\n",
    "mil_features=extract_features(mil_arg_3,mil_bert)[0]\n",
    "mil_embedding=extract_features(mil_arg_3,mil_bert)[1]\n",
    "mil_labels=extract_features(mil_arg_3,mil_bert)[2]\n",
    "#mil_bert.clear()\n",
    "#torch.cuda.empty_cache()\n",
    "#politics\n",
    "pol_features=extract_features(pol_arg_3,pol_bert)[0]\n",
    "pol_embedding=extract_features(pol_arg_3,pol_bert)[1]\n",
    "pol_labels=extract_features(pol_arg_3,pol_bert)[2]\n",
    "#pol_bert.clear()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f29ff",
   "metadata": {},
   "source": [
    "# Only RNN. Argumentative features RNN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "063cea9e",
   "metadata": {},
   "source": [
    "----------------Only 3 labels: Claim, Premises,None----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b3edad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Concatenate, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from keras.layers import Bidirectional, InputLayer, SimpleRNN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from itertools import chain, repeat, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a512f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16623557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 128)          384       \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,409\n",
      "Trainable params: 33,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Argumentative features RNN  architecture\n",
    "input_arg_only= Input(shape=(100,))\n",
    "model_arg_only= Embedding(3, 128)(input_arg_only)\n",
    "model_arg_only= SimpleRNN(128, dropout=0.2)(model_arg_only)\n",
    "dense_pred_arg_only=(Dense(1, activation='sigmoid'))(model_arg_only)\n",
    "\n",
    "model_arg_only= Model(inputs=input_arg_only, outputs=dense_pred_arg_only)\n",
    "model_arg_only.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_score])\n",
    "print(model_arg_only.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a766d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 19s 104ms/step - loss: 0.5405 - accuracy: 0.7689 - f1_score: 0.8639 - val_loss: 0.5333 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 17s 101ms/step - loss: 0.5325 - accuracy: 0.7782 - f1_score: 0.8731 - val_loss: 0.5347 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 17s 101ms/step - loss: 0.5376 - accuracy: 0.7767 - f1_score: 0.8726 - val_loss: 0.5469 - val_accuracy: 0.7753 - val_f1_score: 0.8716\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 17s 101ms/step - loss: 0.5340 - accuracy: 0.7771 - f1_score: 0.8728 - val_loss: 0.5323 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 17s 101ms/step - loss: 0.5340 - accuracy: 0.7773 - f1_score: 0.8720 - val_loss: 0.5326 - val_accuracy: 0.7753 - val_f1_score: 0.8716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac00414dc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation data extraction.Traning data: NYT politics dataset.\n",
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent= train_test_split(pol_arg_3_features,pol_arg_3_labels, \n",
    "    test_size=0.2, random_state= 42)\n",
    "#Fit the Argumentative features RNN to the actual data.\n",
    "model_arg_only.fit(np.array(X_train_sent),np.array(y_train_sent),\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=(np.array(X_test_sent),np.array(y_test_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3f71a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test 3 labels model-----\n",
      "nyt_edu\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 0.5447 - accuracy: 0.7261 - f1_score: 0.8364\n",
      "Test score: 0.5446839928627014\n",
      "Test accuracy: 0.7261320352554321\n",
      "F1 score: 0.8364138603210449\n",
      "nyt_fin\n",
      "96/96 [==============================] - 2s 19ms/step - loss: 0.4430 - accuracy: 0.8236 - f1_score: 0.9012\n",
      "Test score: 0.44299113750457764\n",
      "Test accuracy: 0.8235870599746704\n",
      "F1 score: 0.9012267589569092\n",
      "nyt_law\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 0.5422 - accuracy: 0.7355 - f1_score: 0.8446\n",
      "Test score: 0.5422341227531433\n",
      "Test accuracy: 0.7355113625526428\n",
      "F1 score: 0.8446060419082642\n",
      "nyt_med\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.5280 - accuracy: 0.7357 - f1_score: 0.8435\n",
      "Test score: 0.5280036330223083\n",
      "Test accuracy: 0.7357268929481506\n",
      "F1 score: 0.8434920907020569\n",
      "nyt_mil\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.4550 - accuracy: 0.7956 - f1_score: 0.8846\n",
      "Test score: 0.455048531293869\n",
      "Test accuracy: 0.7955513596534729\n",
      "F1 score: 0.8845686912536621\n"
     ]
    }
   ],
   "source": [
    "print(\"-----Test 3 labels model-----\")\n",
    "for features, labels, name in zip([np.array(edu_arg_3_features),np.array(fin_arg_3_features),np.array(law_arg_3_features),np.array(med_arg_3_features),np.array(mil_arg_3_features)],[np.array(edu_arg_3_labels),np.array(fin_arg_3_labels),np.array(law_arg_3_labels),np.array(med_arg_3_labels),np.array(mil_arg_3_labels)],['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    x_test = sequence.pad_sequences(features, maxlen=100)\n",
    "    score, acc,f1 = model_arg_only.evaluate(x_test, labels, batch_size=32)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed1f8894",
   "metadata": {},
   "source": [
    "----------------Only 6 labels:'assumption','anecdote','testimony','statistics','other','common-ground'-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3babad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 100, 128)          768       \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,793\n",
      "Trainable params: 33,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Argumentative features RNN  architecture\n",
    "input_arg_6_only= Input(shape=(100,))\n",
    "model_arg_6_only= Embedding(6, 128)(input_arg_6_only)\n",
    "model_arg_6_only= SimpleRNN(128, dropout=0.2)(model_arg_6_only)\n",
    "dense_pred_arg_6_only=(Dense(1, activation='sigmoid'))(model_arg_6_only)\n",
    "\n",
    "model_arg_6_only= Model(inputs=input_arg_6_only, outputs=dense_pred_arg_6_only)\n",
    "model_arg_6_only.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_score])\n",
    "print(model_arg_6_only.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d1d7963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 19s 102ms/step - loss: 0.5396 - accuracy: 0.7753 - f1_score: 0.8696 - val_loss: 0.5325 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 17s 100ms/step - loss: 0.5320 - accuracy: 0.7782 - f1_score: 0.8733 - val_loss: 0.5362 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 17s 98ms/step - loss: 0.5448 - accuracy: 0.7782 - f1_score: 0.8730 - val_loss: 0.5263 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 17s 99ms/step - loss: 0.5248 - accuracy: 0.7782 - f1_score: 0.8737 - val_loss: 0.5274 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 17s 99ms/step - loss: 0.5154 - accuracy: 0.7784 - f1_score: 0.8732 - val_loss: 0.5176 - val_accuracy: 0.7760 - val_f1_score: 0.8720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67a4cad610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation data extraction.Traning data: NYT politics dataset.\n",
    "X_train_sent_6, X_test_sent_6, y_train_sent_6, y_test_sent_6= train_test_split(pol_arg_6_features,pol_arg_6_labels, \n",
    "    test_size=0.2, random_state= 42)\n",
    "#Fit the Argumentative features RNN to the actual data.\n",
    "model_arg_6_only.fit(np.array(X_train_sent_6),np.array(y_train_sent_6),\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=(np.array(X_test_sent_6),np.array(y_test_sent_6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2f1a044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test 6 labels model-----\n",
      "nyt_edu\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 0.5812 - accuracy: 0.7258 - f1_score: 0.8360\n",
      "Test score: 0.5812196135520935\n",
      "Test accuracy: 0.7258328795433044\n",
      "F1 score: 0.8359654545783997\n",
      "nyt_fin\n",
      "96/96 [==============================] - 2s 18ms/step - loss: 0.4660 - accuracy: 0.8235 - f1_score: 0.9011\n",
      "Test score: 0.4660411775112152\n",
      "Test accuracy: 0.82347172498703\n",
      "F1 score: 0.9011202454566956\n",
      "nyt_law\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 0.5677 - accuracy: 0.7355 - f1_score: 0.8446\n",
      "Test score: 0.567742109298706\n",
      "Test accuracy: 0.7355113625526428\n",
      "F1 score: 0.8446060419082642\n",
      "nyt_med\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.5719 - accuracy: 0.7357 - f1_score: 0.8435\n",
      "Test score: 0.5719174742698669\n",
      "Test accuracy: 0.7357268929481506\n",
      "F1 score: 0.8434920907020569\n",
      "nyt_mil\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4871 - accuracy: 0.7956 - f1_score: 0.8846\n",
      "Test score: 0.4870593845844269\n",
      "Test accuracy: 0.7955513596534729\n",
      "F1 score: 0.8845686912536621\n"
     ]
    }
   ],
   "source": [
    "print(\"-----Test 6 labels model-----\")\n",
    "for features, labels, name in zip([np.array(edu_arg_6_features),np.array(fin_arg_6_features),np.array(law_arg_6_features),np.array(med_arg_6_features),np.array(mil_arg_6_features)],[np.array(edu_arg_6_labels),np.array(fin_arg_6_labels),np.array(law_arg_6_labels),np.array(med_arg_6_labels),np.array(mil_arg_6_labels)],['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    x_test = sequence.pad_sequences(features, maxlen=100)\n",
    "    score, acc,f1 = model_arg_6_only.evaluate(x_test, labels, batch_size=32)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eadf8a",
   "metadata": {},
   "source": [
    "# Only BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fbedebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BERT embeddings model architecture\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "bert_model = tf.keras.Sequential()\n",
    "bert_model.add(tf.keras.Input(shape=(768)))\n",
    "bert_model.add(tf.keras.layers.Dense(1))\n",
    "bert_model.summary()\n",
    "\n",
    "bert_model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0),f1_score ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf90eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embedding_bert, X_test_embedding_bert, y_train_embedding_bert, y_test_embedding_bert= train_test_split(pol_embedding,pol_labels, \n",
    "    test_size=0.2, random_state= 8)\n",
    "X_train_embedding_bert=tf.stack(X_train_embedding_bert, axis=0)\n",
    "X_test_embedding_bert=tf.stack(X_test_embedding_bert, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ba60cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.3248 - binary_accuracy: 0.8630 - f1_score: 0.9090 - val_loss: 0.3619 - val_binary_accuracy: 0.8492 - val_f1_score: 0.8933\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.3217 - binary_accuracy: 0.8632 - f1_score: 0.9087 - val_loss: 0.3653 - val_binary_accuracy: 0.8507 - val_f1_score: 0.8968\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.3207 - binary_accuracy: 0.8663 - f1_score: 0.9076 - val_loss: 0.3643 - val_binary_accuracy: 0.8507 - val_f1_score: 0.8889\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.3180 - binary_accuracy: 0.8659 - f1_score: 0.9091 - val_loss: 0.3637 - val_binary_accuracy: 0.8492 - val_f1_score: 0.8996\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 0.3169 - binary_accuracy: 0.8659 - f1_score: 0.9072 - val_loss: 0.3605 - val_binary_accuracy: 0.8492 - val_f1_score: 0.8977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab7829a070>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just the embedding.\n",
    "import numpy as np\n",
    "bert_model.fit(X_train_embedding_bert,np.array(y_train_embedding_bert),\n",
    "          batch_size=16,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test_embedding_bert,np.array(y_test_embedding_bert)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efb6ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#education tranform into a tensor\n",
    "edu_features=tf.stack(edu_features, axis=0)\n",
    "edu_embedding=tf.stack(edu_embedding, axis=0)\n",
    "edu_labels=np.array(edu_labels)\n",
    "\n",
    "#finances\n",
    "fin_features=tf.stack(fin_features, axis=0)\n",
    "fin_embedding=tf.stack(fin_embedding, axis=0)\n",
    "fin_labels=np.array(fin_labels)\n",
    "\n",
    "#law\n",
    "law_features=tf.stack(law_features, axis=0)\n",
    "law_embedding=tf.stack(law_embedding, axis=0)\n",
    "law_labels=np.array(law_labels)\n",
    "\n",
    "#medicine\n",
    "medicine_features=tf.stack(medicine_features, axis=0)\n",
    "medicine_embedding=tf.stack(medicine_embedding, axis=0)\n",
    "medicine_labels=np.array(medicine_labels)\n",
    "\n",
    "#military\n",
    "mil_features=tf.stack(mil_features, axis=0)\n",
    "mil_embedding=tf.stack(mil_embedding, axis=0)\n",
    "mil_labels=np.array(mil_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17525c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test only BERT emb. model-----\n",
      "nyt_edu\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.3892 - binary_accuracy: 0.8325 - f1_score: 0.8667\n",
      "Test score: 0.38919612765312195\n",
      "Test accuracy: 0.8325150012969971\n",
      "F1 score: 0.866670548915863\n",
      "nyt_fin\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.3643 - binary_accuracy: 0.8429 - f1_score: 0.8862\n",
      "Test score: 0.3642500042915344\n",
      "Test accuracy: 0.8428618311882019\n",
      "F1 score: 0.8861642479896545\n",
      "nyt_law\n",
      "110/110 [==============================] - 0s 3ms/step - loss: 0.4354 - binary_accuracy: 0.8060 - f1_score: 0.8558\n",
      "Test score: 0.43543386459350586\n",
      "Test accuracy: 0.8059659004211426\n",
      "F1 score: 0.8558492064476013\n",
      "nyt_med\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.4120 - binary_accuracy: 0.8175 - f1_score: 0.8589\n",
      "Test score: 0.4120257794857025\n",
      "Test accuracy: 0.8175397515296936\n",
      "F1 score: 0.8588746190071106\n",
      "nyt_mil\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.3489 - binary_accuracy: 0.8632 - f1_score: 0.8924\n",
      "Test score: 0.34885403513908386\n",
      "Test accuracy: 0.8632276654243469\n",
      "F1 score: 0.8923753499984741\n"
     ]
    }
   ],
   "source": [
    "print(\"-----Test only BERT emb. model-----\")\n",
    "for embeddings, labels, name in zip([edu_embedding,fin_embedding,law_embedding,medicine_embedding,mil_embedding],\n",
    "                                    [np.array(edu_labels),np.array(fin_labels),np.array(law_labels),np.array(medicine_labels),np.array(mil_labels)],\n",
    "                         ['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    score, acc,f1= bert_model.evaluate(embeddings, labels)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956d564",
   "metadata": {},
   "source": [
    "# RNN+BERT merged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83e29e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          98432       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 100, 128)     384         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn_2 (SimpleRNN)       (None, 128)          32896       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['dropout[0][0]',                \n",
      "                                                                  'simple_rnn_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            257         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 131,969\n",
      "Trainable params: 131,969\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import Input, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Concatenate, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from keras.layers import Bidirectional, InputLayer, SimpleRNN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "input_emb = Input(shape=(768,))\n",
    "dense_1 = Dense(128, activation='relu', activity_regularizer=l2(0.0001))(input_emb)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "# dense_2 = Dense(128, activation='sigmoid', activity_regularizer=l2(0.0001))(input_emb)\n",
    "# dropout_2 = Dropout(0.5)(dense_1)\n",
    "\n",
    "input_arg = Input(shape=(100,))\n",
    "model_arg = Embedding(3, 128)(input_arg)\n",
    "model_arg = SimpleRNN(128, dropout=0.2)(model_arg)\n",
    "\n",
    "merged = Concatenate()([dropout_1, model_arg])\n",
    "dense_pred = (Dense(1, activation='sigmoid'))(merged)\n",
    "\n",
    "model_merged_3= Model(inputs=[input_emb, input_arg], outputs=dense_pred)\n",
    "model_merged_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_score])\n",
    "print(model_merged_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f9d989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embedding, X_test_embedding, y_train_embedding, y_test_embedding= train_test_split(pol_embedding,pol_labels, \n",
    "    test_size=0.2, random_state= 8)\n",
    "X_train_features, X_test_features, y_train_features, y_test_features= train_test_split(pol_features,pol_labels, \n",
    "    test_size=0.2, random_state= 8)\n",
    "#We need to stack the embeddings\n",
    "X_train_embedding=tf.stack(X_train_embedding, axis=0)\n",
    "X_train_features=tf.stack(X_train_features, axis=0)\n",
    "X_test_embedding=tf.stack(X_test_embedding, axis=0)\n",
    "X_test_features=tf.stack(X_test_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e06807e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 20s 107ms/step - loss: 0.4285 - accuracy: 0.8152 - f1_score: 0.8857 - val_loss: 0.4085 - val_accuracy: 0.8221 - val_f1_score: 0.8925\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 18s 103ms/step - loss: 0.3815 - accuracy: 0.8408 - f1_score: 0.9010 - val_loss: 0.4044 - val_accuracy: 0.8324 - val_f1_score: 0.8879\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 18s 104ms/step - loss: 0.3633 - accuracy: 0.8491 - f1_score: 0.9048 - val_loss: 0.3732 - val_accuracy: 0.8382 - val_f1_score: 0.8986\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 18s 104ms/step - loss: 0.3530 - accuracy: 0.8498 - f1_score: 0.9063 - val_loss: 0.3738 - val_accuracy: 0.8426 - val_f1_score: 0.9025\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 18s 103ms/step - loss: 0.3427 - accuracy: 0.8566 - f1_score: 0.9097 - val_loss: 0.3851 - val_accuracy: 0.8353 - val_f1_score: 0.9002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6b10574b20>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merged 3 labels\n",
    "import numpy as np\n",
    "model_merged_3.fit([X_train_embedding,X_train_features],np.array(y_train_embedding),\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([X_test_embedding,X_test_features ],np.array(y_test_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "829d9f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test 3 labels merged model-----\n",
      "nyt_edu\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 0.3996 - accuracy: 0.8205 - f1_score: 0.8725\n",
      "Test score: 0.3995703160762787\n",
      "Test accuracy: 0.8205128312110901\n",
      "F1 score: 0.8725488781929016\n",
      "nyt_fin\n",
      "96/96 [==============================] - 2s 19ms/step - loss: 0.3733 - accuracy: 0.8455 - f1_score: 0.9060\n",
      "Test score: 0.3733283281326294\n",
      "Test accuracy: 0.8454753160476685\n",
      "F1 score: 0.9060474038124084\n",
      "nyt_law\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 0.4616 - accuracy: 0.7943 - f1_score: 0.8597\n",
      "Test score: 0.46155232191085815\n",
      "Test accuracy: 0.7943181991577148\n",
      "F1 score: 0.859734296798706\n",
      "nyt_med\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 0.4150 - accuracy: 0.8228 - f1_score: 0.8792\n",
      "Test score: 0.4149516224861145\n",
      "Test accuracy: 0.8228369355201721\n",
      "F1 score: 0.8792459964752197\n",
      "nyt_mil\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3868 - accuracy: 0.8557 - f1_score: 0.8970\n",
      "Test score: 0.38675129413604736\n",
      "Test accuracy: 0.8556554913520813\n",
      "F1 score: 0.8970090746879578\n"
     ]
    }
   ],
   "source": [
    "print(\"-----Test 3 labels merged model-----\")\n",
    "for features, labels, name in zip([[edu_embedding,edu_features],[fin_embedding,fin_features],[law_embedding,law_features],[medicine_embedding,medicine_features],[mil_embedding,mil_features]],[edu_labels,fin_labels,law_labels,medicine_labels,mil_labels],['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    score, acc , f1= model_merged_3.evaluate(features, labels, batch_size=32)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9c745",
   "metadata": {},
   "source": [
    "# MERged 6 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfd5234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_6(unsorted_arg_dataset,unsorted_bert_dataset):\n",
    "    sorted_keys=sorted(unsorted_arg_dataset.keys())\n",
    "    sorted_bert= []\n",
    "    sorted_arg = []\n",
    "    labels=[]\n",
    "    for key in sorted_keys:\n",
    "        if key in unsorted_bert_dataset.keys():\n",
    "            tensor=unsorted_bert_dataset[key]\n",
    "            sorted_bert.append(tensor)\n",
    "            sorted_arg.append(tf.convert_to_tensor(unsorted_arg_dataset[key][0]))\n",
    "            labels.append(unsorted_arg_dataset[key][1])\n",
    "    return sorted_arg,sorted_bert,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6ee1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#education\n",
    "edu_features_6=extract_features_6(edu_arg_6,edu_bert)[0]\n",
    "edu_embedding_6=extract_features_6(edu_arg_6,edu_bert)[1]\n",
    "edu_labels_6=extract_features_6(edu_arg_6,edu_bert)[2]\n",
    "#-------------------------\n",
    "fin_features_6=extract_features_6(fin_arg_6,fin_bert)[0]\n",
    "fin_embedding_6=extract_features_6(fin_arg_6,fin_bert)[1]\n",
    "fin_labels_6=extract_features_6(fin_arg_6,fin_bert)[2]\n",
    "#-------------------------\n",
    "law_features_6=extract_features_6(law_arg_6,law_bert)[0]\n",
    "law_embedding_6=extract_features_6(law_arg_6,law_bert)[1]\n",
    "law_labels_6=extract_features_6(law_arg_6,law_bert)[2]\n",
    "#-------------------------\n",
    "medicine_features_6=extract_features_6(med_arg_6,med_bert)[0]\n",
    "medicine_embedding_6=extract_features_6(med_arg_6,med_bert)[1]\n",
    "medicine_labels_6=extract_features_6(med_arg_6,med_bert)[2]\n",
    "#-------------------------\n",
    "mil_features_6=extract_features_6(mil_arg_6,mil_bert)[0]\n",
    "mil_embedding_6=extract_features_6(mil_arg_6,mil_bert)[1]\n",
    "mil_labels_6=extract_features_6(mil_arg_6,mil_bert)[2]\n",
    "#-------------------------\n",
    "pol_features_6=extract_features_6(pol_arg_6,pol_bert)[0]\n",
    "pol_embedding_6=extract_features_6(pol_arg_6,pol_bert)[1]\n",
    "pol_labels_6=extract_features_6(pol_arg_6,pol_bert)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6799c387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          98432       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 100, 128)     768         ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn_3 (SimpleRNN)       (None, 128)          32896       ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256)          0           ['dropout_1[0][0]',              \n",
      "                                                                  'simple_rnn_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            257         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 132,353\n",
      "Trainable params: 132,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#6 label merged model\n",
    "input_emb = Input(shape=(768,))\n",
    "dense_1 = Dense(128, activation='relu', activity_regularizer=l2(0.0001))(input_emb)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "# dense_2 = Dense(128, activation='sigmoid', activity_regularizer=l2(0.0001))(input_emb)\n",
    "# dropout_2 = Dropout(0.5)(dense_1)\n",
    "\n",
    "input_arg = Input(shape=(100,))\n",
    "model_arg = Embedding(6, 128)(input_arg)\n",
    "model_arg = SimpleRNN(128, dropout=0.2)(model_arg)\n",
    "\n",
    "merged = Concatenate()([dropout_1, model_arg])\n",
    "dense_pred = (Dense(1, activation='sigmoid'))(merged)\n",
    "\n",
    "model_6_merged= Model(inputs=[input_emb, input_arg], outputs=dense_pred)\n",
    "model_6_merged.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_score])\n",
    "print(model_6_merged.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4c2f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 label merged model\n",
    "X_train_embedding_6, X_test_embedding_6, y_train_embedding_6, y_test_embedding_6= train_test_split(pol_embedding_6,pol_labels_6, \n",
    "    test_size=0.2, random_state= 8)\n",
    "X_train_features_6, X_test_features_6, y_train_features_6, y_test_features_6= train_test_split(pol_features_6,pol_labels_6, \n",
    "    test_size=0.2, random_state= 8)\n",
    "#We need to stack the embeddings\n",
    "X_train_embedding_6=tf.stack(X_train_embedding_6, axis=0)\n",
    "X_train_features_6=tf.stack(X_train_features_6, axis=0)\n",
    "X_test_embedding_6=tf.stack(X_test_embedding_6, axis=0)\n",
    "X_test_features_6=tf.stack(X_test_features_6, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c9025d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#education tranform into a tensor\n",
    "edu_features_6=tf.stack(edu_features_6, axis=0)\n",
    "edu_embedding_6=tf.stack(edu_embedding_6, axis=0)\n",
    "edu_labels_6=np.array(edu_labels_6)\n",
    "#finances\n",
    "fin_features_6=tf.stack(fin_features_6, axis=0)\n",
    "fin_embedding_6=tf.stack(fin_embedding_6, axis=0)\n",
    "fin_labels_6=np.array(fin_labels_6)\n",
    "#law\n",
    "law_features_6=tf.stack(law_features_6, axis=0)\n",
    "law_embedding_6=tf.stack(law_embedding_6, axis=0)\n",
    "law_labels_6=np.array(law_labels_6)\n",
    "#medicine\n",
    "medicine_features_6=tf.stack(medicine_features_6, axis=0)\n",
    "medicine_embedding_6=tf.stack(medicine_embedding_6, axis=0)\n",
    "medicine_labels_6=np.array(medicine_labels_6)\n",
    "#military\n",
    "mil_features_6=tf.stack(mil_features_6, axis=0)\n",
    "mil_embedding_6=tf.stack(mil_embedding_6, axis=0)\n",
    "mil_labels_6=np.array(mil_labels_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf9189a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 19s 106ms/step - loss: 0.4236 - accuracy: 0.8156 - f1_score: 0.8854 - val_loss: 0.3985 - val_accuracy: 0.8309 - val_f1_score: 0.8923\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 18s 105ms/step - loss: 0.3834 - accuracy: 0.8326 - f1_score: 0.8955 - val_loss: 0.3840 - val_accuracy: 0.8346 - val_f1_score: 0.8904\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 18s 104ms/step - loss: 0.3607 - accuracy: 0.8460 - f1_score: 0.9045 - val_loss: 0.3647 - val_accuracy: 0.8426 - val_f1_score: 0.9012\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 18s 104ms/step - loss: 0.3528 - accuracy: 0.8509 - f1_score: 0.9065 - val_loss: 0.3822 - val_accuracy: 0.8419 - val_f1_score: 0.8982\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 18s 106ms/step - loss: 0.3392 - accuracy: 0.8603 - f1_score: 0.9125 - val_loss: 0.3579 - val_accuracy: 0.8477 - val_f1_score: 0.9035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67a46987f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merged\n",
    "import numpy as np\n",
    "model_6_merged.fit([X_train_embedding_6,X_train_features_6],np.array(y_train_embedding_6),\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([X_test_embedding_6,X_test_features_6],np.array(y_test_features_6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236a67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test merged  6 label model-----\n",
      "nyt_edu\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.3890 - accuracy: 0.8236 - f1_score: 0.8656\n",
      "Test score: 0.38896244764328003\n",
      "Test accuracy: 0.8235936760902405\n",
      "F1 score: 0.8656309843063354\n",
      "nyt_fin\n",
      "96/96 [==============================] - 2s 19ms/step - loss: 0.3661 - accuracy: 0.8450 - f1_score: 0.9021\n",
      "Test score: 0.36608582735061646\n",
      "Test accuracy: 0.8450474143028259\n",
      "F1 score: 0.9021396040916443\n",
      "nyt_law\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 0.4333 - accuracy: 0.8040 - f1_score: 0.8607\n",
      "Test score: 0.43332797288894653\n",
      "Test accuracy: 0.8039772510528564\n",
      "F1 score: 0.8606530427932739\n",
      "nyt_med\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.4038 - accuracy: 0.8175 - f1_score: 0.8715\n",
      "Test score: 0.40380895137786865\n",
      "Test accuracy: 0.8175397515296936\n",
      "F1 score: 0.8715118169784546\n",
      "nyt_mil\n",
      "13/67 [====>.........................] - ETA: 0s - loss: 0.3441 - accuracy: 0.8654 - f1_score: 0.9130"
     ]
    }
   ],
   "source": [
    "print(\"-----Test merged  6 label model-----\")\n",
    "for features, labels, name in zip([[edu_embedding_6,edu_features_6],[fin_embedding_6,fin_features_6],[law_embedding_6,law_features_6],[medicine_embedding_6,medicine_features_6],[mil_embedding_6,mil_features_6]],[edu_labels_6,fin_labels_6,law_labels_6,medicine_labels_6,mil_labels_6],['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    score, acc , f1= model_6_merged.evaluate(features, labels, batch_size=32)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
