{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0daabe",
   "metadata": {},
   "source": [
    "# Import argumentative features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce81834a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11176]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "tf.keras.backend.clear_session()\n",
    "torch.cuda.empty_cache()\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d5e07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all needed libraries and packages\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import StanfordTagger\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pickle\n",
    "import os\n",
    "from ast import literal_eval\n",
    "from itertools import chain, repeat, islice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d9673",
   "metadata": {},
   "source": [
    "# Import original datasets for VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4ea485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYT-EDU original features: 1881\n",
      "NYT-FIN original features: 3100\n",
      "NYT-LAW original features: 3553\n",
      "NYT-Med original features: 1743\n",
      "NYT-MILL original features: 2132\n",
      "NYT-POL original features: 6886\n"
     ]
    }
   ],
   "source": [
    "#Importing already filtered out datasets from New York Times\n",
    "nyt_edu_original= list(open(\"/data/output_txt/nyt-edu.txt\"))\n",
    "print(\"NYT-EDU original features:\",len(nyt_edu_original ))\n",
    "nyt_fin_original= list(open(\"/data/output_txt/nyt-fin.txt\"))\n",
    "print(\"NYT-FIN original features:\",len(nyt_fin_original))\n",
    "nyt_law_original= list(open(\"/data/output_txt/nyt-law.txt\"))\n",
    "print(\"NYT-LAW original features:\",len(nyt_law_original))\n",
    "nyt_med_original = list(open(\"/data/output_txt/nyt-med.txt\"))\n",
    "print(\"NYT-Med original features:\",len(nyt_med_original))\n",
    "nyt_mil_original= list(open(\"/data/output_txt/nyt-mil.txt\"))\n",
    "print(\"NYT-MILL original features:\",len(nyt_mil_original))\n",
    "nyt_pol_original = list(open(\"/data/output_txt/nyt-pol.txt\"))\n",
    "print(\"NYT-POL original features:\",len(nyt_pol_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5f990",
   "metadata": {},
   "source": [
    "# Import BERT embeddings and Arg. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385fd8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def extract_arg_features(dataset):\n",
    "    arg_features=[]\n",
    "    arg_labels=[]\n",
    "    texts_order=[]\n",
    "    arg_features_dict={}\n",
    "    for s in dataset:\n",
    "        text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "        text=text.replace('\"',\"\")\n",
    "        tokenized=nltk.sent_tokenize(text)\n",
    "        if len(tokenized)<=100:\n",
    "            texts_order.append(text)\n",
    "            sequence=literal_eval(s.split(\"\\t\")[2].split(\"\\n\")[0])\n",
    "            label=s.split(\"\\t\")[0]\n",
    "            if label=='editorial':\n",
    "                label=0\n",
    "            elif label=='news':\n",
    "                label=1\n",
    "            arg_features.append(sequence)\n",
    "            arg_labels.append(label)\n",
    "            arg_features_dict[text]=(sequence,label)\n",
    "    return arg_features_dict,arg_features,arg_labels,texts_order\n",
    "\n",
    "\n",
    "def get_bert_embeddings(name):\n",
    "    directory = '/data/BertEmbeddings/'+str(name)\n",
    "    # Create empty dictionary to save data\n",
    "    bert_dict= {}\n",
    "    # Loop over files and read pickles\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.pickle'):\n",
    "            with open(str(\"/data/BertEmbeddings/\"+str(name)+\"/\"+str(file)), 'rb') as f:\n",
    "                bert_f=pickle.load(f)\n",
    "                article= bert_f['article']\n",
    "                article=article.replace('\"',\"\")\n",
    "                tokenized=nltk.sent_tokenize(article)\n",
    "                if len(tokenized)<=100:\n",
    "                    bert_emb= bert_f['bert_emb'][0]\n",
    "                    bert_dict[article] =tf.convert_to_tensor(bert_emb.cpu())\n",
    "    return bert_dict\n",
    "\n",
    "def extract_features(unsorted_arg_dataset,unsorted_bert_dataset,texts_order_list):\n",
    "    sorted_keys=texts_order_list\n",
    "    sorted_bert= []\n",
    "    sorted_arg = []\n",
    "    labels=[]\n",
    "    h=[]\n",
    "    for key in sorted_keys:\n",
    "        h.append(key)\n",
    "        tensor=unsorted_bert_dataset[key]\n",
    "        sorted_bert.append(tensor)\n",
    "        if key in unsorted_arg_dataset:\n",
    "            sorted_arg.append(tf.convert_to_tensor(unsorted_arg_dataset[key][0]))\n",
    "            labels.append(unsorted_arg_dataset[key][1])\n",
    "    return sorted_arg,sorted_bert,labels,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916d1409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYT-EDU argumentative features: 1833\n",
      "NYT-FIN argumentative features: 3061\n",
      "NYfT-LAW argumentative features: 3520\n",
      "NYT-Med argumentative features: 1699\n",
      "NYT-MILL argumentative features: 2113\n",
      "NYT-POL argumentative features: 6826\n"
     ]
    }
   ],
   "source": [
    "#Argumentative features.3 labels\n",
    "nyt_edu_arg = list(open(\"/data/output_txt/nyt-edu-argfeat.txt\"))\n",
    "edu_arg_3,edu_arg_3_features,edu_arg_3_labels, edu_order=extract_arg_features(nyt_edu_arg)\n",
    "print(\"NYT-EDU argumentative features:\",len(edu_arg_3))\n",
    "nyt_fin_arg = list(open(\"/data/output_txt/nyt-fin-argfeat.txt\"))\n",
    "fin_arg_3,fin_arg_3_features,fin_arg_3_labels, fin_order=extract_arg_features(nyt_fin_arg)\n",
    "print(\"NYT-FIN argumentative features:\",len(fin_arg_3))\n",
    "nyt_law_arg = list(open(\"/data/output_txt/nyt-law-argfeat.txt\"))\n",
    "law_arg_3,law_arg_3_features,law_arg_3_labels, law_order=extract_arg_features(nyt_law_arg)\n",
    "print(\"NYfT-LAW argumentative features:\",len(law_arg_3))\n",
    "nyt_med_arg = list(open(\"/data/output_txt/nyt-med-argfeat.txt\"))\n",
    "med_arg_3,med_arg_3_features,med_arg_3_labels,med_order=extract_arg_features(nyt_med_arg)\n",
    "print(\"NYT-Med argumentative features:\",len(med_arg_3))\n",
    "nyt_mil_arg = list(open(\"/data/output_txt/nyt-mil-argfeat.txt\"))\n",
    "mil_arg_3,mil_arg_3_features,mil_arg_3_labels, mil_order=extract_arg_features(nyt_mil_arg)\n",
    "print(\"NYT-MILL argumentative features:\",len(mil_arg_3))\n",
    "nyt_pol_arg = list(open(\"/data/output_txt/nyt-pol-argfeat.txt\"))\n",
    "pol_arg_3,pol_arg_3_features,pol_arg_3_labels, pol_order=extract_arg_features(nyt_pol_arg)\n",
    "print(\"NYT-POL argumentative features:\",len(pol_arg_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ee2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYT publishers and dataset size of argumentative features with 3 labels:'assumption','anecdote','testimony','statistics','other','common-ground'\n",
      "NYT-EDU arg features: 1831\n",
      "NYT-FIN arg features: 3059\n",
      "NYT-LAW arg features: 3520\n",
      "NYT-Med arg features: 1699\n",
      "NYT-MILL arg features: 2113\n",
      "NYT-POL arg features: 6826\n"
     ]
    }
   ],
   "source": [
    "#Argumentative features.6 labels\n",
    "print(\"NYT publishers and dataset size of argumentative features with 3 labels:'assumption','anecdote','testimony','statistics','other','common-ground'\")\n",
    "nyt_edu_6_arg = list(open(\"nyt-edu-argfeat-6.txt\"))\n",
    "edu_arg_6,edu_arg_6_features,edu_arg_6_labels, edu_order_6=extract_arg_features(nyt_edu_6_arg)\n",
    "print(\"NYT-EDU arg features:\",len(edu_arg_6))\n",
    "nyt_fin_6_arg = list(open(\"/data/output_txt/nyt-fin-argfeat-6.txt\"))\n",
    "fin_arg_6,fin_arg_6_features,fin_arg_6_labels, fin_order_6=extract_arg_features(nyt_fin_6_arg)\n",
    "print(\"NYT-FIN arg features:\",len(fin_arg_6))\n",
    "nyt_law_6_arg = list(open(\"/data/output_txt/nyt-law-argfeat-6.txt\"))\n",
    "law_arg_6,law_arg_6_features,law_arg_6_labels, law_order_6=extract_arg_features(nyt_law_6_arg)\n",
    "print(\"NYT-LAW arg features:\",len(law_arg_6))\n",
    "nyt_med_6_arg = list(open(\"/data/output_txt/nyt-med-argfeat-6.txt\"))\n",
    "med_arg_6,med_arg_6_features,med_arg_6_labels,med_order_6=extract_arg_features(nyt_med_6_arg)\n",
    "print(\"NYT-Med arg features:\",len(med_arg_6))\n",
    "nyt_mil_6_arg = list(open(\"/data/output_txt/nyt-mil-argfeat-6.txt\"))\n",
    "mil_arg_6,mil_arg_6_features,mil_arg_6_labels, mil_order_6=extract_arg_features(nyt_mil_6_arg)\n",
    "print(\"NYT-MILL arg features:\",len(mil_arg_6))\n",
    "nyt_pol_6_arg = list(open(\"/data/output_txt/nyt-pol-argfeat-6.txt\"))\n",
    "pol_arg_6,pol_arg_6_features,pol_arg_6_labels, pol_order_6=extract_arg_features(nyt_pol_6_arg)\n",
    "print(\"NYT-POL arg features:\",len(pol_arg_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a3a02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 08:31:05.358949: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 08:31:05.884610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9745 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Arg. Feature=Embeddings: Education True\n",
      "Length Arg. Feature=Embeddings: Finances- True\n",
      "Length Arg. Feature=Embeddings: Law- True\n",
      "Length Arg. Feature=Embeddings: Medicine- True\n",
      "Length Arg. Feature=Embeddings: Military- True\n",
      "Length Arg. Feature=Embeddings: Politics- True\n"
     ]
    }
   ],
   "source": [
    "#education\n",
    "edu_bert=get_bert_embeddings(\"NytEduBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Education\",len(edu_arg_3)==len(edu_bert))\n",
    "#finances\n",
    "fin_bert=get_bert_embeddings(\"NytFinBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Finances-\",len(fin_arg_3)==len(fin_bert))\n",
    "#law \n",
    "law_bert=get_bert_embeddings(\"NytLawBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Law-\",len(law_arg_3)==len(law_bert))\n",
    "#medicine \n",
    "med_bert=get_bert_embeddings(\"NytMedBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Medicine-\",len(med_arg_3)==len(med_bert))\n",
    "#military\n",
    "mil_bert=get_bert_embeddings(\"NytMillBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Military-\",len(mil_arg_3)==len(mil_bert))\n",
    "#politics\n",
    "pol_bert=get_bert_embeddings(\"NytPolBert\")\n",
    "print(\"Length Arg. Feature=Embeddings:\",\"Politics-\",len(pol_arg_3)==len(pol_bert))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80eb3f7d",
   "metadata": {},
   "source": [
    "------------------------3 labels------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb73adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"NYT publishers and dataset size of argumentative features with 3 labels:Claim, Premises,None\"\n",
    "#education\n",
    "edu_features=extract_features(edu_arg_3,edu_bert,edu_order)[0]\n",
    "edu_embedding=extract_features(edu_arg_3,edu_bert,edu_order)[1]\n",
    "edu_labels=extract_features(edu_arg_3,edu_bert,edu_order)[2]\n",
    "edu_list=extract_features(edu_arg_3,edu_bert,edu_order)[3]\n",
    "#tranform into a tensor\n",
    "edu_features=tf.stack(edu_features, axis=0)\n",
    "edu_embedding=tf.stack(edu_embedding, axis=0)\n",
    "edu_labels=np.array(edu_labels)\n",
    "\n",
    "#finances\n",
    "fin_features=extract_features(fin_arg_3,fin_bert,fin_order)[0]\n",
    "fin_embedding=extract_features(fin_arg_3,fin_bert,fin_order)[1]\n",
    "fin_labels=extract_features(fin_arg_3,fin_bert,fin_order)[2]\n",
    "fin_list=extract_features(fin_arg_3,fin_bert,fin_order)[3]\n",
    "#tranform into a tensor\n",
    "fin_features=tf.stack(fin_features, axis=0)\n",
    "fin_embedding=tf.stack(fin_embedding, axis=0)\n",
    "fin_labels=np.array(fin_labels)\n",
    "\n",
    "#law\n",
    "law_features=extract_features(law_arg_3,law_bert,law_order)[0]\n",
    "law_embedding=extract_features(law_arg_3,law_bert,law_order)[1]\n",
    "law_labels=extract_features(law_arg_3,law_bert,law_order)[2]\n",
    "#tranform into a tensor\n",
    "law_features=tf.stack(law_features, axis=0)\n",
    "law_embedding=tf.stack(law_embedding, axis=0)\n",
    "law_labels=np.array(law_labels)\n",
    "\n",
    "#medicine\n",
    "medicine_features=extract_features(med_arg_3,med_bert,med_order)[0]\n",
    "medicine_embedding=extract_features(med_arg_3,med_bert,med_order)[1]\n",
    "medicine_labels=extract_features(med_arg_3,med_bert,med_order)[2]\n",
    "#tranform into a tensor\n",
    "medicine_features=tf.stack(medicine_features, axis=0)\n",
    "medicine_embedding=tf.stack(medicine_embedding, axis=0)\n",
    "medicine_labels=np.array(medicine_labels)\n",
    "\n",
    "#military\n",
    "mil_features=extract_features(mil_arg_3,mil_bert,mil_order)[0]\n",
    "mil_embedding=extract_features(mil_arg_3,mil_bert,mil_order)[1]\n",
    "mil_labels=extract_features(mil_arg_3,mil_bert,mil_order)[2]\n",
    "#tranform into a tensor\n",
    "mil_features=tf.stack(mil_features, axis=0)\n",
    "mil_embedding=tf.stack(mil_embedding, axis=0)\n",
    "mil_labels=np.array(mil_labels)\n",
    "#politics\n",
    "pol_features=extract_features(pol_arg_3,pol_bert,pol_order)[0]\n",
    "pol_embedding=extract_features(pol_arg_3,pol_bert,pol_order)[1]\n",
    "pol_labels=extract_features(pol_arg_3,pol_bert,pol_order)[2]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2c22d0b",
   "metadata": {},
   "source": [
    "------------------------6 labels------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4885f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#education\n",
    "edu_features_6=extract_features(edu_arg_6,edu_bert,edu_order_6)[0]\n",
    "edu_embedding_6=extract_features(edu_arg_6,edu_bert,edu_order_6)[1]\n",
    "edu_labels_6=extract_features(edu_arg_6,edu_bert,edu_order_6)[2]\n",
    "#tranform into a tensor\n",
    "edu_features_6=tf.stack(edu_features_6, axis=0)\n",
    "edu_embedding_6=tf.stack(edu_embedding_6, axis=0)\n",
    "edu_labels_6=np.array(edu_labels_6)\n",
    "\n",
    "#finances\n",
    "fin_features_6=extract_features(fin_arg_6,fin_bert,fin_order_6)[0]\n",
    "fin_embedding_6=extract_features(fin_arg_6,fin_bert,fin_order_6)[1]\n",
    "fin_labels_6=extract_features(fin_arg_6,fin_bert,fin_order_6)[2]\n",
    "#tranform into a tensor\n",
    "fin_features_6=tf.stack(fin_features_6, axis=0)\n",
    "fin_embedding_6=tf.stack(fin_embedding_6, axis=0)\n",
    "fin_labels_6=np.array(fin_labels_6)\n",
    "\n",
    "#law\n",
    "law_features_6=extract_features(law_arg_6,law_bert,law_order_6)[0]\n",
    "law_embedding_6=extract_features(law_arg_6,law_bert,law_order_6)[1]\n",
    "law_labels_6=extract_features(law_arg_6,law_bert,law_order_6)[2]\n",
    "#tranform into a tensor\n",
    "law_features_6=tf.stack(law_features_6, axis=0)\n",
    "law_embedding_6=tf.stack(law_embedding_6, axis=0)\n",
    "law_labels_6=np.array(law_labels_6)\n",
    "\n",
    "#medicine\n",
    "medicine_features_6=extract_features(med_arg_6,med_bert,med_order_6)[0]\n",
    "medicine_embedding_6=extract_features(med_arg_6,med_bert,med_order_6)[1]\n",
    "medicine_labels_6=extract_features(med_arg_6,med_bert,med_order_6)[2]\n",
    "#tranform into a tensor\n",
    "medicine_features_6=tf.stack(medicine_features_6, axis=0)\n",
    "medicine_embedding_6=tf.stack(medicine_embedding_6, axis=0)\n",
    "medicine_labels_6=np.array(medicine_labels_6)\n",
    "\n",
    "#military\n",
    "mil_features_6=extract_features(mil_arg_6,mil_bert,mil_order_6)[0]\n",
    "mil_embedding_6=extract_features(mil_arg_6,mil_bert,mil_order_6)[1]\n",
    "mil_labels_6=extract_features(mil_arg_6,mil_bert,mil_order_6)[2]\n",
    "#tranform into a tensor\n",
    "mil_features_6=tf.stack(mil_features_6, axis=0)\n",
    "mil_embedding_6=tf.stack(mil_embedding_6, axis=0)\n",
    "mil_labels_6=np.array(mil_labels_6)\n",
    "#politics\n",
    "pol_features_6=extract_features(pol_arg_6,pol_bert,pol_order_6)[0]\n",
    "pol_embedding_6=extract_features(pol_arg_6,pol_bert,pol_order_6)[1]\n",
    "pol_labels_6=extract_features(pol_arg_6,pol_bert,pol_order_6)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefda344",
   "metadata": {},
   "source": [
    "# VADER for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7621d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All helper  functions needeed for implementing the Vader model\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "#Vader gives a dictionary as output we need to transfer it to a integer\n",
    "def format_output(output_dict):\n",
    "    if(output_dict['compound']>= 0.05):\n",
    "        polarity =1 #positive=1\n",
    "    elif(output_dict['compound']<= -0.05):\n",
    "        polarity =2 #negative=2\n",
    "    else:\n",
    "        polarity =3 #neural=3\n",
    "    return polarity\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    output_dict =  sid.polarity_scores(text)\n",
    "    return format_output(output_dict)\n",
    "\n",
    "#As the number of sentences are different we need to pad to 100 sentences at maximun.\n",
    "def pad_infinite(iterable, padding=None):\n",
    "    return chain(iterable, repeat(padding))\n",
    "\n",
    "def pad(iterable, size, padding=None):\n",
    "    return list(islice(pad_infinite(iterable, padding), size))\n",
    "\n",
    "#The main function of sentiment extraction.\n",
    "def sentiment_dataset_extraction(example_dataset):\n",
    "    main_label_list=[]\n",
    "    sentiment_labels_list=[]\n",
    "    for s in example_dataset:\n",
    "        text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "        split_text = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
    "        if len(split_text)<=100:\n",
    "            text_sentiment=[]\n",
    "            label=s.split(\"\\t\")[0]\n",
    "            if label=='editorial':\n",
    "                label=0\n",
    "            elif label=='news':\n",
    "                label=1\n",
    "            for sent in split_text:\n",
    "                sentence_sentiment=predict_sentiment(sent)\n",
    "                text_sentiment.append(sentence_sentiment)\n",
    "            padded_sentence=pad(text_sentiment,100,0)\n",
    "            sentiment_labels_list.append(padded_sentence)\n",
    "            main_label_list.append(label)\n",
    "    return sentiment_labels_list,main_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b494572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the sentiment fromt the dataset\n",
    "#First variable is list with sentiment tensors and the second variable is a list with labels.\n",
    "edu_sentiments,edu_labels_sentiments=sentiment_dataset_extraction(nyt_edu_original)\n",
    "edu_sentiments=np.array(edu_sentiments)\n",
    "fin_sentiments,fin_labels_sentiments=sentiment_dataset_extraction(nyt_fin_original)\n",
    "fin_sentiments=np.array(fin_sentiments)\n",
    "law_sentiments,law_labels_sentiments=sentiment_dataset_extraction(nyt_law_original)\n",
    "law_sentiments=np.array(law_sentiments)\n",
    "med_sentiments,med_labels_sentiments=sentiment_dataset_extraction(nyt_med_original)\n",
    "med_sentiments=np.array(med_sentiments)\n",
    "mil_sentiments,mil_labels_sentiments=sentiment_dataset_extraction(nyt_mil_original)\n",
    "mil_sentiments=np.array(mil_sentiments)\n",
    "pol_sentiments,pol_labels_sentiments=sentiment_dataset_extraction(nyt_pol_original)\n",
    "pol_sentiments=np.array(pol_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4d3b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 6 label \n",
    "banned_edu=set(edu_order).difference(set(edu_order_6))\n",
    "banned_fin=set(fin_order).difference(set(fin_order_6))\n",
    "all_banned=banned_edu.union(banned_fin)\n",
    "def sentiment_dataset_extraction_6(example_dataset):\n",
    "    main_label_list=[]\n",
    "    sentiment_labels_list=[]\n",
    "    for s in example_dataset:\n",
    "        text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "        split_text = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
    "        if len(split_text)<=100:\n",
    "            text=text.replace('\"',\"\")\n",
    "            if text not in all_banned:\n",
    "                text_sentiment=[]\n",
    "                label=s.split(\"\\t\")[0]\n",
    "                if label=='editorial':\n",
    "                    label=0\n",
    "                elif label=='news':\n",
    "                    label=1\n",
    "                for sent in split_text:\n",
    "                    sentence_sentiment=predict_sentiment(sent)\n",
    "                    text_sentiment.append(sentence_sentiment)\n",
    "                padded_sentence=pad(text_sentiment,100,0)\n",
    "                sentiment_labels_list.append(padded_sentence)\n",
    "                main_label_list.append(label)\n",
    "    return sentiment_labels_list,main_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8b84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_sentiments_6,edu_labels_sentiments_6=sentiment_dataset_extraction_6(nyt_edu_original)\n",
    "edu_sentiments_6=np.array(edu_sentiments_6)\n",
    "fin_sentiments_6,fin_labels_sentiments_6=sentiment_dataset_extraction_6(nyt_fin_original)\n",
    "fin_sentiments_6=np.array(fin_sentiments_6)\n",
    "law_sentiments_6,law_labels_sentiments_6=sentiment_dataset_extraction_6(nyt_law_original)\n",
    "law_sentiments_6=np.array(law_sentiments_6)\n",
    "med_sentiments_6,med_labels_sentiments_6=sentiment_dataset_extraction_6(nyt_med_original)\n",
    "med_sentiments_6=np.array(med_sentiments_6)\n",
    "mil_sentiments_6,mil_labels_sentiments_6=sentiment_dataset_extraction_6(nyt_mil_original)\n",
    "mil_sentiments_6=np.array(mil_sentiments_6)\n",
    "pol_sentiments_6,pol_labels_sentiments_6=sentiment_dataset_extraction_6(nyt_pol_original)\n",
    "pol_sentiments_6=np.array(pol_sentiments_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10bb173",
   "metadata": {},
   "source": [
    "# Stanford POS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88274de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the percentage of documents in all documents that have more than 100 sentences? 1.2593936252915263\n"
     ]
    }
   ],
   "source": [
    "#The English Penn Treebank tagset is used for Stanford POS model,we need to tranfser them to numbers.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "pos_tags={ \"CC\":1,\"CD\":2,\"DT\":3,\"EX\":4,\"FW\":5,\n",
    "\"IN\":6,\"JJ\":7,\"JJR\":8,\"JJS\":9,\"LS\":10,\"MD\":11,\n",
    "\"NN\":12,\"NNS\":13,\"NNP\":14,\"NNPS\":15,\"PDT\":16,\"POS\":17,\n",
    "\"PRP\":18,\"PRP$\":19,\"RB\":20,\"RBR\":21,\"RBS\":22,\"RP\":23,\n",
    "\"SYM\":24,\"TO\":25,\"UH\":26,\"VB\":27,\"VBD\":28,\"VBG\":29,\n",
    "\"VBN\":30,\"VBP\":31,\"VBZ\":32,\"WDT\":33,\"WP\":34,\"WP$\":35,\"WRB\":36}\n",
    "\n",
    "#How many documents there are that contain more than 100 sentences in one document?\n",
    "def check_sentence_length(example_sets):\n",
    "    check_lemmas={}\n",
    "    for example_set in example_sets:\n",
    "        for s in example_set:\n",
    "            pos_list_text=[]\n",
    "            label=s.split(\"\\t\")[0]\n",
    "            if label=='editorial':\n",
    "                label=0\n",
    "            elif label=='news':\n",
    "                label=1\n",
    "            text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "            split_text = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
    "            if len(split_text) not in check_lemmas:\n",
    "                check_lemmas[len(split_text)]=0\n",
    "            check_lemmas[len(split_text)]+=1\n",
    "    return check_lemmas\n",
    "\n",
    "#Imply the model\n",
    "sentence_length_dict=check_sentence_length((nyt_edu_original,nyt_fin_original,nyt_law_original,nyt_med_original,nyt_mil_original,nyt_pol_original))\n",
    "count_more_100=0\n",
    "general_number_documents=sum(sentence_length_dict.values())\n",
    "for k,v in sentence_length_dict.items():\n",
    "    if k>100:\n",
    "        count_more_100+=v\n",
    "percentage_less_100=(count_more_100/general_number_documents)*100\n",
    "print(\"What is the percentage of documents in all documents that have more than 100 sentences?\",percentage_less_100)\n",
    "#This means that more than 98% of the whole dataset contains of sentences with length less than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f8ee33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofzeros = [0] *100\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def pos_tagger(pos_example_dataset):\n",
    "    pos_data=[]\n",
    "    pos_label=[]\n",
    "    for s in pos_example_dataset:\n",
    "        pos_list_text=[]\n",
    "        text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "        split_text = nltk.sent_tokenize(text)\n",
    "        if len(split_text)<=100:\n",
    "            for sent in split_text:\n",
    "                pos_list_sentence=[]\n",
    "                pos_analyzed=nltk.pos_tag(tokenizer.tokenize(sent))\n",
    "                for word in pos_analyzed:\n",
    "                    try:\n",
    "                        pos_list_sentence.append(pos_tags[word[1]])\n",
    "                    except:\n",
    "                        pass\n",
    "                pos_list_sentence=pad(pos_list_sentence,100,0)\n",
    "                pos_list_text.append(pos_list_sentence)\n",
    "            label=s.split(\"\\t\")[0]\n",
    "            if label=='editorial':\n",
    "                label=0\n",
    "            elif label=='news':\n",
    "                label=1\n",
    "            if len(pos_list_text)<=100:\n",
    "                pos_list_text=pad(pos_list_text,100,listofzeros)\n",
    "            pos_tensor=tf.convert_to_tensor(pos_list_text)\n",
    "            pos_data.append(pos_tensor)\n",
    "            pos_label.append(label)\n",
    "    return pos_data,pos_label\n",
    "def pos_tagger_6(pos_example_dataset):\n",
    "    pos_data=[]\n",
    "    pos_label=[]\n",
    "    for s in pos_example_dataset:\n",
    "        pos_list_text=[]\n",
    "        text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "        split_text = nltk.sent_tokenize(text)\n",
    "        if len(split_text)<=100:\n",
    "            for sent in split_text:\n",
    "                pos_list_sentence=[]\n",
    "                pos_analyzed=nltk.pos_tag(tokenizer.tokenize(sent))\n",
    "                for word in pos_analyzed:\n",
    "                    try:\n",
    "                        pos_list_sentence.append(pos_tags[word[1]])\n",
    "                    except:\n",
    "                        pass\n",
    "                pos_list_sentence=pad(pos_list_sentence,100,0)\n",
    "                pos_list_text.append(pos_list_sentence)\n",
    "            label=s.split(\"\\t\")[0]\n",
    "            if label=='editorial':\n",
    "                label=0\n",
    "            elif label=='news':\n",
    "                label=1\n",
    "            if len(pos_list_text)<=100:\n",
    "                pos_list_text=pad(pos_list_text,100,listofzeros)\n",
    "            pos_tensor=tf.convert_to_tensor(pos_list_text)\n",
    "            pos_data.append(pos_tensor)\n",
    "            pos_label.append(label)\n",
    "    return pos_data,pos_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4597b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_pos_data,edu_pos_labels=pos_tagger(nyt_edu_original)\n",
    "edu_pos_data=np.array(edu_pos_data)\n",
    "fin_pos_data,fin_pos_labels=pos_tagger(nyt_fin_original)\n",
    "fin_pos_data=np.array(fin_pos_data)\n",
    "law_pos_data,law_pos_labels=pos_tagger(nyt_law_original)\n",
    "law_pos_data=np.array(law_pos_data)\n",
    "med_pos_data,med_pos_labels=pos_tagger(nyt_med_original)\n",
    "med_pos_data=np.array(med_pos_data)\n",
    "mil_pos_data,mil_pos_labels=pos_tagger(nyt_mil_original)\n",
    "mil_pos_data=np.array(mil_pos_data)\n",
    "pol_pos_data,pol_pos_labels=pos_tagger(nyt_pol_original)\n",
    "pol_pos_data=np.array(pol_pos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af4b0bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_pos_labels==pol_labels_sentiments==pol_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b92f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 6 label \n",
    "def pos_tagger_6(pos_example_dataset):\n",
    "    pos_data=[]\n",
    "    pos_label=[]\n",
    "    for s in pos_example_dataset:\n",
    "        pos_list_text=[]\n",
    "        text=s.split(\"\\t\")[1].split(\"\\n\")[0]\n",
    "        split_text = nltk.sent_tokenize(text)\n",
    "        if len(split_text)<=100:\n",
    "            text=text.replace('\"',\"\")\n",
    "            if text not in all_banned:\n",
    "                for sent in split_text:\n",
    "                    pos_list_sentence=[]\n",
    "                    pos_analyzed=nltk.pos_tag(tokenizer.tokenize(sent))\n",
    "                    for word in pos_analyzed:\n",
    "                        try:\n",
    "                            pos_list_sentence.append(pos_tags[word[1]])\n",
    "                        except:\n",
    "                            pass\n",
    "                    pos_list_sentence=pad(pos_list_sentence,100,0)\n",
    "                    pos_list_text.append(pos_list_sentence)\n",
    "                label=s.split(\"\\t\")[0]\n",
    "                if label=='editorial':\n",
    "                    label=0\n",
    "                elif label=='news':\n",
    "                    label=1\n",
    "                if len(pos_list_text)<=100:\n",
    "                    pos_list_text=pad(pos_list_text,100,listofzeros)\n",
    "                pos_tensor=tf.convert_to_tensor(pos_list_text)\n",
    "                pos_data.append(pos_tensor)\n",
    "                pos_label.append(label)\n",
    "    return pos_data,pos_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c3e8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_pos_data_6,edu_pos_labels_6=pos_tagger_6(nyt_edu_original)\n",
    "edu_pos_data_6=np.array(edu_pos_data_6)\n",
    "fin_pos_data_6,fin_pos_labels_6=pos_tagger_6(nyt_fin_original)\n",
    "fin_pos_data_6=np.array(fin_pos_data_6)\n",
    "law_pos_data_6,law_pos_labels_6=pos_tagger_6(nyt_law_original)\n",
    "law_pos_data_6=np.array(law_pos_data_6)\n",
    "med_pos_data_6,med_pos_labels_6=pos_tagger_6(nyt_med_original)\n",
    "med_pos_data_6=np.array(med_pos_data_6)\n",
    "mil_pos_data_6,mil_pos_labels_6=pos_tagger_6(nyt_mil_original)\n",
    "mil_pos_data_6=np.array(mil_pos_data_6)\n",
    "pol_pos_data_6,pol_pos_labels_6=pos_tagger_6(nyt_pol_original)\n",
    "pol_pos_data_6=np.array(pol_pos_data_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffadee35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_pos_labels_6==fin_labels_sentiments_6==fin_labels_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f29ff",
   "metadata": {},
   "source": [
    "# Merging  4 models: VADER,POS,BERT,Arg. Features.3 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b3edad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Concatenate, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from keras.layers import Bidirectional, InputLayer, SimpleRNN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from itertools import chain, repeat, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a512f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e29e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          98432       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 100, 128)     384         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 100, 128)     384         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 100, 100)]   0           []                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " simple_rnn (SimpleRNN)         (None, 128)          32896       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " simple_rnn_1 (SimpleRNN)       (None, 128)          32896       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " simple_rnn_2 (SimpleRNN)       (None, 128)          29312       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 512)          0           ['dropout[0][0]',                \n",
      "                                                                  'simple_rnn[0][0]',             \n",
      "                                                                  'simple_rnn_1[0][0]',           \n",
      "                                                                  'simple_rnn_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            513         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 194,817\n",
      "Trainable params: 194,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#The architecture of  BERT+Arg.Feature+VADER+POS merged\n",
    "input_emb = Input(shape=(768,))\n",
    "dense_1 = Dense(128, activation='relu', activity_regularizer=l2(0.0001))(input_emb)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "\n",
    "input_arg = Input(shape=(100,))\n",
    "model_arg = Embedding(3, 128)(input_arg)\n",
    "model_arg = SimpleRNN(128, dropout=0.2)(model_arg)\n",
    "\n",
    "input_sentiment = Input(shape=(100,))\n",
    "model_sentiment = Embedding(3, 128)(input_sentiment)\n",
    "model_sentiment = SimpleRNN(128, dropout=0.2)(model_sentiment)\n",
    "\n",
    "input_pos= Input(pol_pos_data[0].shape)\n",
    "model_pos= SimpleRNN(128, dropout=0.1)(input_pos)\n",
    "\n",
    "\n",
    "merged = Concatenate()([dropout_1, model_arg,model_sentiment,model_pos])\n",
    "dense_pred = (Dense(1, activation='sigmoid'))(merged)\n",
    "\n",
    "model_all_merged= Model(inputs=[input_emb, input_arg,input_sentiment,input_pos], outputs=dense_pred)\n",
    "model_all_merged.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_score])\n",
    "print(model_all_merged.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f9d989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding\n",
    "X_train_embedding, X_test_embedding, y_train_embedding, y_test_embedding= train_test_split(pol_embedding,pol_labels, \n",
    "    test_size=0.2, random_state= 42)\n",
    "X_train_embedding=tf.stack(X_train_embedding, axis=0)                          \n",
    "X_test_embedding=tf.stack(X_test_embedding, axis=0)\n",
    "#features\n",
    "X_train_features, X_test_features, y_train_features, y_test_features= train_test_split(pol_features,pol_labels, \n",
    "    test_size=0.2, random_state= 42)\n",
    "X_train_features=tf.stack(X_train_features, axis=0)\n",
    "X_test_features=tf.stack(X_test_features, axis=0)\n",
    "\n",
    "#POS\n",
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos= train_test_split(pol_pos_data,pol_pos_labels, \n",
    "    test_size=0.2, random_state= 42)\n",
    "X_train_pos=tf.stack(X_train_pos, axis=0)\n",
    "X_test_pos=tf.stack(X_test_pos, axis=0)\n",
    "\n",
    "#Sentiment\n",
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent= train_test_split(pol_sentiments, pol_labels, \n",
    "    test_size=0.2, random_state= 42)\n",
    "X_train_sent=tf.stack(X_train_sent, axis=0)\n",
    "X_test_sent=tf.stack(X_test_sent, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e06807e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 38s 208ms/step - loss: 0.4337 - accuracy: 0.8123 - f1_score: 0.8846 - val_loss: 0.3893 - val_accuracy: 0.8382 - val_f1_score: 0.8984\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 35s 203ms/step - loss: 0.3834 - accuracy: 0.8410 - f1_score: 0.9013 - val_loss: 0.3832 - val_accuracy: 0.8338 - val_f1_score: 0.8980\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 35s 204ms/step - loss: 0.3594 - accuracy: 0.8500 - f1_score: 0.9062 - val_loss: 0.3684 - val_accuracy: 0.8433 - val_f1_score: 0.9049\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 35s 205ms/step - loss: 0.3547 - accuracy: 0.8526 - f1_score: 0.9074 - val_loss: 0.3751 - val_accuracy: 0.8485 - val_f1_score: 0.9042\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 34s 201ms/step - loss: 0.3435 - accuracy: 0.8566 - f1_score: 0.9092 - val_loss: 0.3767 - val_accuracy: 0.8426 - val_f1_score: 0.9049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe61c8b26d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merged\n",
    "import numpy as np\n",
    "model_all_merged.fit([X_train_embedding,X_train_features,X_train_sent,X_train_pos],np.array(y_train_embedding),\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([X_test_embedding,X_test_features,X_test_sent,X_test_pos],np.array(y_test_features)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0b7ee97",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "829d9f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyt_edu\n",
      "58/58 [==============================] - 2s 27ms/step - loss: 0.3956 - accuracy: 0.8167 - f1_score: 0.8807\n",
      "Test score: 0.39559465646743774\n",
      "Test accuracy: 0.8166939616203308\n",
      "F1 score: 0.8807132840156555\n",
      "nyt_fin\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.3657 - accuracy: 0.8497 - f1_score: 0.9121\n",
      "Test score: 0.3657127320766449\n",
      "Test accuracy: 0.8497223258018494\n",
      "F1 score: 0.9121111035346985\n",
      "nyt_law\n",
      "110/110 [==============================] - 4s 28ms/step - loss: 0.4574 - accuracy: 0.7940 - f1_score: 0.8696\n",
      "Test score: 0.45738667249679565\n",
      "Test accuracy: 0.7940340638160706\n",
      "F1 score: 0.8695864081382751\n",
      "nyt_med\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.4143 - accuracy: 0.8205 - f1_score: 0.8842\n",
      "Test score: 0.41425877809524536\n",
      "Test accuracy: 0.820482611656189\n",
      "F1 score: 0.8841903209686279\n",
      "nyt_mil\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 0.3738 - accuracy: 0.8552 - f1_score: 0.9132\n",
      "Test score: 0.37382471561431885\n",
      "Test accuracy: 0.8551822304725647\n",
      "F1 score: 0.913189709186554\n"
     ]
    }
   ],
   "source": [
    "for features, labels, name in zip([[edu_embedding,edu_features,edu_sentiments,edu_pos_data],[fin_embedding,fin_features,fin_sentiments,fin_pos_data],[law_embedding,law_features,law_sentiments,law_pos_data],[medicine_embedding,medicine_features,med_sentiments,med_pos_data],[mil_embedding,mil_features,mil_sentiments,mil_pos_data]],[edu_labels,fin_labels,law_labels,medicine_labels,mil_labels],['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    score, acc , f1= model_all_merged.evaluate(features, labels, batch_size=32)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16657f7",
   "metadata": {},
   "source": [
    "#  6 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ec57186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          98432       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 100, 128)     768         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 100, 128)     384         ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 100, 100)]   0           []                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn_3 (SimpleRNN)       (None, 128)          32896       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " simple_rnn_4 (SimpleRNN)       (None, 128)          32896       ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " simple_rnn_5 (SimpleRNN)       (None, 128)          29312       ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 512)          0           ['dropout_1[0][0]',              \n",
      "                                                                  'simple_rnn_3[0][0]',           \n",
      "                                                                  'simple_rnn_4[0][0]',           \n",
      "                                                                  'simple_rnn_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            513         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 195,201\n",
      "Trainable params: 195,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#The architecture of  BERT+Arg.Feature+VADER+POS merged\n",
    "input_emb = Input(shape=(768,))\n",
    "dense_1 = Dense(128, activation='relu', activity_regularizer=l2(0.0001))(input_emb)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "\n",
    "input_arg = Input(shape=(100,))\n",
    "model_arg = Embedding(6, 128)(input_arg)\n",
    "model_arg = SimpleRNN(128, dropout=0.2)(model_arg)\n",
    "\n",
    "input_sentiment = Input(shape=(100,))\n",
    "model_sentiment = Embedding(3, 128)(input_sentiment)\n",
    "model_sentiment = SimpleRNN(128, dropout=0.2)(model_sentiment)\n",
    "\n",
    "input_pos= Input(pol_pos_data_6[0].shape)\n",
    "model_pos= SimpleRNN(128, dropout=0.1)(input_pos)\n",
    "\n",
    "\n",
    "merged = Concatenate()([dropout_1, model_arg,model_sentiment,model_pos])\n",
    "dense_pred = (Dense(1, activation='sigmoid'))(merged)\n",
    "\n",
    "model_all_merged_6= Model(inputs=[input_emb, input_arg,input_sentiment,input_pos], outputs=dense_pred)\n",
    "model_all_merged_6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_score])\n",
    "print(model_all_merged_6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5d22df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 41s 223ms/step - loss: 0.4344 - accuracy: 0.8150 - f1_score: 0.8858 - val_loss: 0.4046 - val_accuracy: 0.8199 - val_f1_score: 0.8928\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 37s 217ms/step - loss: 0.3746 - accuracy: 0.8447 - f1_score: 0.9029 - val_loss: 0.3794 - val_accuracy: 0.8455 - val_f1_score: 0.9013\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 38s 223ms/step - loss: 0.3590 - accuracy: 0.8504 - f1_score: 0.9060 - val_loss: 0.4172 - val_accuracy: 0.8294 - val_f1_score: 0.8982\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 38s 222ms/step - loss: 0.3569 - accuracy: 0.8467 - f1_score: 0.9034 - val_loss: 0.3664 - val_accuracy: 0.8499 - val_f1_score: 0.9061\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 38s 221ms/step - loss: 0.3387 - accuracy: 0.8560 - f1_score: 0.9092 - val_loss: 0.3760 - val_accuracy: 0.8441 - val_f1_score: 0.9054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe338273fa0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding\n",
    "X_train_6_embedding, X_test_6_embedding, y_train_6_embedding, y_test_6_embedding= train_test_split(pol_embedding_6,pol_labels_6, \n",
    "    test_size=0.2, random_state= 42)\n",
    "X_train_6_embedding=tf.stack(X_train_6_embedding, axis=0)                          \n",
    "X_test_6_embedding=tf.stack(X_test_6_embedding, axis=0)\n",
    "#features\n",
    "X_train_6_features, X_test_6_features, y_train_6_features, y_test_6_features= train_test_split(pol_features_6,pol_labels_6, \n",
    "    test_size=0.2, random_state= 42)\n",
    "X_train_6_features=tf.stack(X_train_6_features, axis=0)\n",
    "X_test_6_features=tf.stack(X_test_6_features, axis=0)\n",
    "\n",
    "#POS\n",
    "X_train_6_pos, X_test_6_pos, y_train_6_pos, y_test_6_pos= train_test_split(pol_pos_data_6,pol_pos_labels_6, \n",
    "    test_size=0.2, random_state= 42)\n",
    "X_train_6_pos=tf.stack(X_train_6_pos, axis=0)\n",
    "X_test_6_pos=tf.stack(X_test_6_pos, axis=0)\n",
    "\n",
    "#Sentiment\n",
    "X_train_6_sent, X_test_6_sent, y_train_6_sent, y_test_6_sent= train_test_split(pol_sentiments_6, pol_labels_6, \n",
    "    test_size=0.2, random_state= 42)\n",
    "X_train_6_sent=tf.stack(X_train_6_sent, axis=0)\n",
    "X_test_6_sent=tf.stack(X_test_6_sent, axis=0)\n",
    "#Merged\n",
    "import numpy as np\n",
    "model_all_merged_6.fit([X_train_6_embedding,X_train_6_features,X_train_6_sent,X_train_6_pos],np.array(y_train_6_embedding),\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=([X_test_6_embedding,X_test_6_features,X_test_6_sent,X_test_6_pos],np.array(y_test_6_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9477aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 6 labels merged model\n",
      "nyt_edu\n",
      "58/58 [==============================] - 2s 28ms/step - loss: 0.3924 - accuracy: 0.8247 - f1_score: 0.8850\n",
      "Test score: 0.39236950874328613\n",
      "Test accuracy: 0.8246859908103943\n",
      "F1 score: 0.8850213885307312\n",
      "nyt_fin\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.3620 - accuracy: 0.8503 - f1_score: 0.9117\n",
      "Test score: 0.36195164918899536\n",
      "Test accuracy: 0.850277841091156\n",
      "F1 score: 0.9116807579994202\n",
      "nyt_law\n",
      "110/110 [==============================] - 4s 29ms/step - loss: 0.4505 - accuracy: 0.8011 - f1_score: 0.8730\n",
      "Test score: 0.45051947236061096\n",
      "Test accuracy: 0.8011363744735718\n",
      "F1 score: 0.8729512095451355\n",
      "nyt_med\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.4127 - accuracy: 0.8193 - f1_score: 0.8818\n",
      "Test score: 0.41269487142562866\n",
      "Test accuracy: 0.8193054795265198\n",
      "F1 score: 0.8817641139030457\n",
      "nyt_mil\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.3595 - accuracy: 0.8632 - f1_score: 0.9173\n",
      "Test score: 0.35945335030555725\n",
      "Test accuracy: 0.8632276654243469\n",
      "F1 score: 0.9173408150672913\n"
     ]
    }
   ],
   "source": [
    "print(\"Test 6 labels merged model\")\n",
    "for features, labels, name in zip([[edu_embedding_6,edu_features_6,edu_sentiments_6,edu_pos_data_6],[fin_embedding_6,fin_features_6,fin_sentiments_6,fin_pos_data_6],[law_embedding_6,law_features_6,law_sentiments_6,law_pos_data_6],[medicine_embedding_6,medicine_features_6,med_sentiments_6,med_pos_data_6],[mil_embedding_6,mil_features_6,mil_sentiments_6,mil_pos_data_6]],[edu_labels_6,fin_labels_6,law_labels_6,medicine_labels_6,mil_labels_6],['nyt_edu', 'nyt_fin', 'nyt_law', 'nyt_med',\"nyt_mil\"]):\n",
    "    print(name)\n",
    "    score, acc , f1= model_all_merged_6.evaluate(features, labels, batch_size=32)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94634639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
